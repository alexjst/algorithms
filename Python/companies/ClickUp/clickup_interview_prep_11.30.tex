\documentclass[11pt,a4paper]{article}
\usepackage[margin=1in]{geometry}
\usepackage{xcolor}
\usepackage{tcolorbox}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{amssymb}

% Configure hyperref for blue links without boxes
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue,
    citecolor=blue,
    filecolor=blue
}

% Define custom colors
\definecolor{problemblue}{RGB}{41, 128, 185}
\definecolor{solutiongreen}{RGB}{39, 174, 96}
\definecolor{testpurple}{RGB}{142, 68, 173}
\definecolor{warningorange}{RGB}{230, 126, 34}
\definecolor{tipblue}{RGB}{52, 152, 219}

% Define colored boxes
\newtcolorbox{problembox}{
    colback=problemblue!5,
    colframe=problemblue,
    title=Problem,
    fonttitle=\bfseries
}

\newtcolorbox{solutionbox}{
    colback=solutiongreen!5,
    colframe=solutiongreen,
    title=Solution,
    fonttitle=\bfseries
}

\newtcolorbox{testbox}{
    colback=testpurple!5,
    colframe=testpurple,
    title=Test Cases,
    fonttitle=\bfseries
}

\newtcolorbox{warningbox}{
    colback=warningorange!5,
    colframe=warningorange,
    title=Important Edge Cases \& Gotchas,
    fonttitle=\bfseries
}

\newtcolorbox{tipbox}{
    colback=tipblue!5,
    colframe=tipblue,
    title=Pro Tips,
    fonttitle=\bfseries
}

\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{red},
    showstringspaces=false,
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny\color{gray}
}

\title{\textbf{ClickUp Backend Interview\\Document Event Processing}}
\author{Complete Preparation Guide - November 30, 2024 (v2)}
\date{\today}

\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Interview Overview}

\subsection{What to Expect}

\textbf{Interview Type:} Backend Live Coding (60 minutes)

\textbf{Format:}
\begin{itemize}
    \item CodeSignal platform (browser-based IDE)
    \item No pre-written test suite
    \item You must test your own code
    \item Recommended language: Python
    \item Focus on correctness, edge cases, and code quality
\end{itemize}

\textbf{Problem Domain:}
\begin{itemize}
    \item Event processing in memory
    \item Document state management (similar to Google Docs)
    \item Real-time collaborative editing
    \item ClickUp's core functionality
\end{itemize}

\subsection{Success Criteria}

\begin{enumerate}
    \item \textbf{Correctness}: Handle all test cases including edge cases
    \item \textbf{Code Quality}: Clean, readable, well-structured code
    \item \textbf{Communication}: Think out loud, explain your approach
    \item \textbf{Testing}: Demonstrate testing strategy
    \item \textbf{Problem-Solving}: Handle follow-up questions and variations
\end{enumerate}

\newpage

\section{Core Problem: Document Event Processor}

\begin{problembox}
\textbf{Context:} ClickUp has a feature that allows users to create documents similar to Google Docs. Changes are tracked through batches of events.

\vspace{10pt}
\textbf{Task:} Process events on a document and return the correctly updated document.

\vspace{10pt}
\textbf{Data Structures:}

\textbf{Document:}
\begin{verbatim}
{
    title: string,
    content: string,          // Lines separated by \n
    lastUpdated: timestamp,
    createdOn: timestamp
}
\end{verbatim}

\textbf{Event:}
\begin{verbatim}
{
    event_id: number,
    event_name: string,       // Case-insensitive: "append", "APPEND", "Append"
    payload: object,
    timestamp: timestamp
}
\end{verbatim}

\vspace{10pt}
\textbf{Event Types:}

1. \textbf{append} - Add content to a specific line
\begin{verbatim}
payload: {
    newContent: string,
    startLine: number        // 1-indexed (line 1 = first line)
}
\end{verbatim}
\textbf{Important:} If content exists at that line, \textbf{append} newContent to the end of that line (don't replace!).

2. \textbf{delete} - Delete all content from document
\begin{verbatim}
payload: {}  // Empty
\end{verbatim}

\vspace{10pt}
\textbf{Requirements:}
\begin{itemize}
    \item Process events in timestamp order (may arrive out-of-order)
    \item Update document.lastUpdated to latest event timestamp
    \item Handle case-insensitive event names
    \item Return updated document object
\end{itemize}
\end{problembox}

\begin{warningbox}
\textbf{IMPORTANT NOTE:} The provided examples show lastUpdated incrementing by 1 (123456789 → 123456790), but event timestamps are in the billions (1641024000001). This appears to be an inconsistency in the problem statement.

\vspace{10pt}
\textbf{Most logical interpretation:} Set lastUpdated to the timestamp of the most recent event.

\vspace{10pt}
\textbf{Action:} Ask the interviewer to clarify this behavior before coding!
\end{warningbox}

\newpage

\section{CRITICAL: Questions to Ask First!}

\begin{tipbox}
\textbf{Before you start coding, ask these clarifying questions:}

\begin{enumerate}
    \item \textbf{lastUpdated behavior:} "Should lastUpdated be set to the timestamp of the latest event, or should it be incremented by 1?"
    \begin{itemize}
        \item The examples show inconsistent behavior - clarify this!
        \item Most logical: use the latest event's timestamp
    \end{itemize}

    \item \textbf{Invalid line numbers:} "What should happen if startLine is 0 or negative?"
    \begin{itemize}
        \item Skip the event? Return error? Assume line 1?
    \end{itemize}

    \item \textbf{Event validation:} "Should I validate event structure and handle malformed events?"
    \begin{itemize}
        \item Missing required fields?
        \item Unknown event types?
    \end{itemize}

    \item \textbf{Same timestamp:} "If multiple events have the same timestamp, what determines their order?"
    \begin{itemize}
        \item Use event\_id as tiebreaker?
        \item Stable sort (preserve original order)?
    \end{itemize}

    \item \textbf{Document mutation:} "Should I modify the input document in place or return a new copy?"
    \begin{itemize}
        \item Safer to return a copy
        \item But in-place is more efficient
    \end{itemize}

    \item \textbf{Content initialization:} "If document doesn't have a content field initially, should I initialize it as empty string?"

    \item \textbf{Trailing newlines:} "Should the final content have a trailing newline character?"
\end{enumerate}

\vspace{10pt}
\textbf{These questions show you think critically and catch ambiguities!}
\end{tipbox}

\newpage

\section{Examples with Step-by-Step Trace}

\subsection{Example 1: Multiple Appends}

\textbf{Input:}
\begin{lstlisting}
events = [
    {"event_id": 1, "event_name": "append",
     "payload": {"newContent": "Line 1 ", "startLine": 1},
     "timestamp": 1641024000001},
    {"event_id": 2, "event_name": "APPEND",
     "payload": {"newContent": "Line 2 ", "startLine": 2},
     "timestamp": 1641024000002},
    {"event_id": 3, "event_name": "APPEND",
     "payload": {"newContent": "Line 3 ", "startLine": 3},
     "timestamp": 1641024000003}
]

document = {"title": "Lorem Ipsum", "lastUpdated": 123456789, "createdOn": 123456789}
\end{lstlisting}

\textbf{Step-by-Step Execution:}
\begin{verbatim}
Initial state:
  lines = []
  lastUpdated = 123456789

After Event 1 (append to line 1):
  lines = ["Line 1 "]
  lastUpdated = 1641024000001

After Event 2 (append to line 2):
  lines = ["Line 1 ", "Line 2 "]
  lastUpdated = 1641024000002

After Event 3 (append to line 3):
  lines = ["Line 1 ", "Line 2 ", "Line 3 "]
  lastUpdated = 1641024000003

Final: Join lines with "\n"
  content = "Line 1 \nLine 2 \nLine 3 "
\end{verbatim}

\textbf{Expected Output:}
\begin{lstlisting}
{
    "title": "Lorem Ipsum",
    "content": "Line 1 \nLine 2 \nLine 3 ",
    "lastUpdated": 1641024000003,
    "createdOn": 123456789
}
\end{lstlisting}

\subsection{Example 2: Delete Event}

\textbf{Input:}
\begin{lstlisting}
events = [{"event_id": 1, "event_name": "delete", "timestamp": 1641024000000}]

document = {
    "title": "Lorem Ipsum",
    "content": "This is Lorem ipsum",
    "lastUpdated": 123456789,
    "createdOn": 123456789
}
\end{lstlisting}

\textbf{Step-by-Step:}
\begin{verbatim}
Initial state:
  lines = ["This is Lorem ipsum"]

After Event 1 (delete):
  lines = []
  content = ""
  lastUpdated = 1641024000000
\end{verbatim}

\textbf{Expected Output:}
\begin{lstlisting}
{
    "title": "Lorem Ipsum",
    "content": "",
    "lastUpdated": 1641024000000,
    "createdOn": 123456789
}
\end{lstlisting}

\newpage

\section{Solution Strategy}

\subsection{Approach}

\begin{enumerate}
    \item \textbf{Sort events by timestamp} (handle out-of-order delivery)
    \item \textbf{Initialize content} as list of lines
    \item \textbf{Process each event} in order:
    \begin{itemize}
        \item For \texttt{append}: Update/create line at specified position
        \item For \texttt{delete}: Clear all content
    \end{itemize}
    \item \textbf{Join lines} back into string with \textbackslash n
    \item \textbf{Update lastUpdated} to latest event timestamp
    \item \textbf{Return updated document}
\end{enumerate}

\subsection{Key Insights}

\begin{itemize}
    \item Use \textbf{list for lines} - O(1) indexing, easy modification
    \item Handle \textbf{1-indexed lines} (convert to 0-indexed: \texttt{line\_idx = start\_line - 1})
    \item \textbf{Extend list} with empty strings if startLine exceeds current length
    \item Event names are \textbf{case-insensitive} (use \texttt{.lower()})
    \item \textbf{Append, don't replace} - use \texttt{lines[idx] += new\_content}
    \item Return a \textbf{copy} to avoid modifying input (safer)
\end{itemize}

\subsection{Why List Over String Manipulation?}

\begin{itemize}
    \item \textbf{Strings are immutable} in Python - expensive to modify
    \item \textbf{List operations} are O(1) for append and indexed assignment
    \item \textbf{Only convert} to string once at the end
    \item Much more efficient for multiple operations
\end{itemize}

\newpage

\section{Complete Solution}

\begin{solutionbox}
\textbf{Clean Production-Ready Implementation}

\begin{lstlisting}
def execute(events, document):
    """
    Process document events and return updated document.

    This solution handles:
    - Out-of-order events (sorts by timestamp)
    - Case-insensitive event names
    - Line gaps (fills with empty strings)
    - Multiple appends to same line
    - Document without initial content

    Args:
        events: List of event dictionaries
        document: Document dictionary

    Returns:
        New document dictionary with processed changes
    """
    # Handle empty events - return unchanged
    if not events:
        return document

    # Sort events by timestamp (handle out-of-order delivery)
    sorted_events = sorted(events, key=lambda e: e["timestamp"])

    # Initialize content as list of lines
    content = document.get("content", "")
    lines = content.split("\n") if content else []

    # Track latest timestamp for lastUpdated
    latest_timestamp = document.get("lastUpdated", 0)

    # Process each event in chronological order
    for event in sorted_events:
        event_name = event["event_name"].lower()
        timestamp = event["timestamp"]

        if event_name == "append":
            payload = event["payload"]
            new_content = payload["newContent"]
            start_line = payload["startLine"]  # 1-indexed

            # Convert to 0-indexed
            line_idx = start_line - 1

            # Extend lines list if necessary (fill gaps with empty strings)
            while len(lines) <= line_idx:
                lines.append("")

            # Append to existing line content (don't replace!)
            lines[line_idx] += new_content

        elif event_name == "delete":
            # Clear all content
            lines = []

        # Update to most recent timestamp
        latest_timestamp = max(latest_timestamp, timestamp)

    # Create result (don't modify input)
    result = document.copy()
    result["content"] = "\n".join(lines)
    result["lastUpdated"] = latest_timestamp

    return result
\end{lstlisting}

\textbf{Time Complexity:} O(n log n + n*m) where:
\begin{itemize}
    \item n = number of events
    \item m = average line length
    \item Sorting: O(n log n)
    \item Processing: O(n) events × O(m) average line operations
\end{itemize}

\textbf{Space Complexity:} O(L) where L = total lines in final document
\end{solutionbox}

\newpage

\section{Robust Version with Validation}

\begin{solutionbox}
\textbf{Enterprise Version with Error Handling}

\begin{lstlisting}
def execute_robust(events, document):
    """
    Robust version with comprehensive validation and error handling.
    Use this if interviewer asks about production considerations.
    """
    # Validate inputs
    if not events:
        return document.copy()

    if not isinstance(events, list):
        raise ValueError("events must be a list")

    if not isinstance(document, dict):
        raise ValueError("document must be a dictionary")

    # Sort by timestamp (with fallback for missing timestamps)
    sorted_events = sorted(events, key=lambda e: e.get("timestamp", 0))

    # Initialize content
    content = document.get("content", "")
    lines = content.split("\n") if content else []

    # Remove trailing empty line if present (from content ending in \n)
    if lines and lines[-1] == "":
        lines = lines[:-1]

    latest_timestamp = document.get("lastUpdated", 0)

    # Process each event with validation
    for event in sorted_events:
        # Validate event structure
        if not isinstance(event, dict):
            continue  # Skip malformed events

        event_name = event.get("event_name", "").lower()
        timestamp = event.get("timestamp", 0)
        payload = event.get("payload", {})

        if event_name == "append":
            # Validate payload
            new_content = payload.get("newContent", "")
            start_line = payload.get("startLine", 1)

            # Validate line number (must be positive)
            if start_line < 1:
                continue  # Skip invalid line numbers

            line_idx = start_line - 1

            # Extend lines if needed
            while len(lines) <= line_idx:
                lines.append("")

            # Append content
            lines[line_idx] += new_content

        elif event_name == "delete":
            # Clear all content
            lines = []

        # Update timestamp
        latest_timestamp = max(latest_timestamp, timestamp)

    # Build result
    result = document.copy()
    result["content"] = "\n".join(lines)
    result["lastUpdated"] = latest_timestamp

    return result
\end{lstlisting}
\end{solutionbox}

\newpage

\section{Critical Edge Cases}

\begin{warningbox}
\textbf{YOU MUST HANDLE THESE:}

\begin{enumerate}
    \item \textbf{Empty Events List}
    \begin{lstlisting}
events = []
# Should return document unchanged
    \end{lstlisting}

    \item \textbf{Out-of-Order Events} - CRITICAL!
    \begin{lstlisting}
events = [
    {"event_id": 2, ..., "timestamp": 102},  # Second
    {"event_id": 1, ..., "timestamp": 101}   # First
]
# Must sort by timestamp before processing!
    \end{lstlisting}

    \item \textbf{Case-Insensitive Event Names}
    \begin{lstlisting}
"append", "APPEND", "Append", "aPpEnD"  # All valid
# Use event_name.lower() for comparison
    \end{lstlisting}

    \item \textbf{Multiple Appends to Same Line} - MUST APPEND, NOT REPLACE!
    \begin{lstlisting}
events = [
    {"payload": {"newContent": "Hello ", "startLine": 1}, ...},
    {"payload": {"newContent": "World", "startLine": 1}, ...}
]
# Result: lines[0] = "Hello World" NOT "World"
    \end{lstlisting}

    \item \textbf{Gap in Line Numbers}
    \begin{lstlisting}
events = [{"payload": {"newContent": "Line5", "startLine": 5}, ...}]
# Result: lines = ["", "", "", "", "Line5"]
# Fill gaps with empty strings!
    \end{lstlisting}

    \item \textbf{Delete Then Append}
    \begin{lstlisting}
events = [
    {"event_name": "delete", "timestamp": 100},
    {"event_name": "append", "payload": {..., "startLine": 1}, "timestamp": 101}
]
# Delete clears lines = [], then append starts fresh
    \end{lstlisting}

    \item \textbf{Document Without Content Field}
    \begin{lstlisting}
document = {"title": "Test", "lastUpdated": 0, "createdOn": 0}
# No "content" key initially
# Use document.get("content", "") to handle safely
    \end{lstlisting}

    \item \textbf{Empty Payload or Missing Fields}
    \begin{lstlisting}
{"event_name": "delete", "timestamp": 100}
# Delete has no payload - that's valid
# Use payload.get("key", default) for safety
    \end{lstlisting}

    \item \textbf{Line Number 0 or Negative}
    \begin{lstlisting}
{"payload": {"newContent": "X", "startLine": 0}, ...}
{"payload": {"newContent": "Y", "startLine": -1}, ...}
# Invalid! Lines are 1-indexed. Skip or error.
    \end{lstlisting}

    \item \textbf{Same Timestamp, Different Events}
    \begin{lstlisting}
events = [
    {"event_id": 1, ..., "timestamp": 100},
    {"event_id": 2, ..., "timestamp": 100}  # Same timestamp!
]
# Python's sort is stable - preserves original order
# Or ask interviewer: use event_id as tiebreaker?
    \end{lstlisting}
\end{enumerate}
\end{warningbox}

\newpage

\section{Comprehensive Test Suite}

\begin{testbox}
\begin{lstlisting}
def test_document_processor():
    """Complete test suite covering all edge cases."""

    print("Running comprehensive test suite...")

    # Test 1: Basic append to empty document
    print("\n[Test 1] Basic append")
    events = [{
        "event_id": 1,
        "event_name": "append",
        "payload": {"newContent": "Hello", "startLine": 1},
        "timestamp": 100
    }]
    doc = {"title": "Test", "lastUpdated": 0, "createdOn": 0}
    result = execute(events, doc)
    assert result["content"] == "Hello", f"Expected 'Hello', got '{result['content']}'"
    assert result["lastUpdated"] == 100, f"Expected 100, got {result['lastUpdated']}"
    print("  PASSED")

    # Test 2: Multiple appends to different lines
    print("\n[Test 2] Multiple lines")
    events = [
        {"event_id": 1, "event_name": "append",
         "payload": {"newContent": "Line1", "startLine": 1},
         "timestamp": 100},
        {"event_id": 2, "event_name": "append",
         "payload": {"newContent": "Line2", "startLine": 2},
         "timestamp": 101}
    ]
    doc = {"title": "Test", "lastUpdated": 0, "createdOn": 0}
    result = execute(events, doc)
    assert result["content"] == "Line1\nLine2"
    print("  PASSED")

    # Test 3: Multiple appends to SAME line (critical!)
    print("\n[Test 3] Same line appends (CRITICAL)")
    events = [
        {"event_id": 1, "event_name": "append",
         "payload": {"newContent": "Hello ", "startLine": 1},
         "timestamp": 100},
        {"event_id": 2, "event_name": "append",
         "payload": {"newContent": "World", "startLine": 1},
         "timestamp": 101}
    ]
    doc = {"title": "Test", "lastUpdated": 0, "createdOn": 0}
    result = execute(events, doc)
    assert result["content"] == "Hello World", \
        f"Must APPEND not replace! Got: '{result['content']}'"
    print("  PASSED")

    # Test 4: Delete event
    print("\n[Test 4] Delete clears all content")
    events = [{"event_id": 1, "event_name": "delete", "timestamp": 100}]
    doc = {"title": "Test", "content": "Some content",
           "lastUpdated": 0, "createdOn": 0}
    result = execute(events, doc)
    assert result["content"] == ""
    print("  PASSED")

    # Test 5: Delete then append
    print("\n[Test 5] Delete then append")
    events = [
        {"event_id": 1, "event_name": "delete", "timestamp": 100},
        {"event_id": 2, "event_name": "append",
         "payload": {"newContent": "New", "startLine": 1},
         "timestamp": 101}
    ]
    doc = {"title": "Test", "content": "Old", "lastUpdated": 0, "createdOn": 0}
    result = execute(events, doc)
    assert result["content"] == "New"
    print("  PASSED")

    # Test 6: Out-of-order events (CRITICAL!)
    print("\n[Test 6] Out-of-order events (CRITICAL)")
    events = [
        {"event_id": 2, "event_name": "append",
         "payload": {"newContent": "Second", "startLine": 2},
         "timestamp": 102},  # Later timestamp
        {"event_id": 1, "event_name": "append",
         "payload": {"newContent": "First", "startLine": 1},
         "timestamp": 101}   # Earlier timestamp
    ]
    doc = {"title": "Test", "lastUpdated": 0, "createdOn": 0}
    result = execute(events, doc)
    assert result["content"] == "First\nSecond", \
        "Must sort by timestamp!"
    print("  PASSED")

    # Test 7: Case-insensitive event names
    print("\n[Test 7] Case-insensitive names")
    events = [
        {"event_id": 1, "event_name": "APPEND",
         "payload": {"newContent": "A", "startLine": 1}, "timestamp": 100},
        {"event_id": 2, "event_name": "Append",
         "payload": {"newContent": "B", "startLine": 2}, "timestamp": 101},
        {"event_id": 3, "event_name": "aPpEnD",
         "payload": {"newContent": "C", "startLine": 3}, "timestamp": 102}
    ]
    doc = {"title": "Test", "lastUpdated": 0, "createdOn": 0}
    result = execute(events, doc)
    assert result["content"] == "A\nB\nC"
    print("  PASSED")

    # Test 8: Gap in line numbers
    print("\n[Test 8] Gap in line numbers")
    events = [{
        "event_id": 1,
        "event_name": "append",
        "payload": {"newContent": "Line5", "startLine": 5},
        "timestamp": 100
    }]
    doc = {"title": "Test", "lastUpdated": 0, "createdOn": 0}
    result = execute(events, doc)
    lines = result["content"].split("\n")
    assert len(lines) == 5, f"Expected 5 lines, got {len(lines)}"
    assert lines[4] == "Line5", f"Expected 'Line5' at index 4, got '{lines[4]}'"
    assert lines[0] == "", "Empty lines should fill gap"
    print("  PASSED")

    # Test 9: Empty events list
    print("\n[Test 9] Empty events")
    events = []
    doc = {"title": "Test", "content": "Original",
           "lastUpdated": 50, "createdOn": 0}
    result = execute(events, doc)
    assert result["content"] == "Original"
    assert result["lastUpdated"] == 50
    print("  PASSED")

    # Test 10: Document without content field
    print("\n[Test 10] No initial content field")
    events = [{
        "event_id": 1,
        "event_name": "append",
        "payload": {"newContent": "New", "startLine": 1},
        "timestamp": 100
    }]
    doc = {"title": "Test", "lastUpdated": 0, "createdOn": 0}  # No "content"
    result = execute(events, doc)
    assert result["content"] == "New"
    print("  PASSED")

    # Test 11: Existing content with append
    print("\n[Test 11] Append to existing content")
    events = [{
        "event_id": 1,
        "event_name": "append",
        "payload": {"newContent": " more", "startLine": 1},
        "timestamp": 100
    }]
    doc = {"title": "Test", "content": "Existing",
           "lastUpdated": 0, "createdOn": 0}
    result = execute(events, doc)
    assert result["content"] == "Existing more"
    print("  PASSED")

    # Test 12: Mixed operations
    print("\n[Test 12] Complex mixed operations")
    events = [
        {"event_id": 1, "event_name": "append",
         "payload": {"newContent": "A", "startLine": 1}, "timestamp": 100},
        {"event_id": 2, "event_name": "append",
         "payload": {"newContent": "B", "startLine": 2}, "timestamp": 101},
        {"event_id": 3, "event_name": "append",
         "payload": {"newContent": "1", "startLine": 1}, "timestamp": 102},
        {"event_id": 4, "event_name": "append",
         "payload": {"newContent": "C", "startLine": 3}, "timestamp": 103}
    ]
    doc = {"title": "Test", "lastUpdated": 0, "createdOn": 0}
    result = execute(events, doc)
    assert result["content"] == "A1\nB\nC"
    print("  PASSED")

    print("\n" + "="*50)
    print("ALL TESTS PASSED!")
    print("="*50)

if __name__ == "__main__":
    test_document_processor()
\end{lstlisting}
\end{testbox}

\newpage

\section{Debugging Strategy}

\begin{tipbox}
\textbf{If Your Tests Are Failing:}

\begin{enumerate}
    \item \textbf{Add Debug Prints}
    \begin{lstlisting}
for event in sorted_events:
    print(f"Processing: {event['event_name']} at line {event.get('payload', {}).get('startLine')}")
    print(f"Lines before: {lines}")
    # ... process event ...
    print(f"Lines after: {lines}")
    print()
    \end{lstlisting}

    \item \textbf{Check Event Sorting}
    \begin{lstlisting}
print("Events before sorting:")
for e in events:
    print(f"  {e['event_id']}: timestamp={e['timestamp']}")

sorted_events = sorted(events, key=lambda e: e["timestamp"])

print("\nEvents after sorting:")
for e in sorted_events:
    print(f"  {e['event_id']}: timestamp={e['timestamp']}")
    \end{lstlisting}

    \item \textbf{Verify Line Indexing}
    \begin{lstlisting}
print(f"startLine={start_line} (1-indexed)")
print(f"line_idx={line_idx} (0-indexed)")
print(f"lines length before: {len(lines)}")
# ... extend lines ...
print(f"lines length after: {len(lines)}")
    \end{lstlisting}

    \item \textbf{Check Append vs Replace}
    \begin{lstlisting}
print(f"Line {line_idx} before: '{lines[line_idx]}'")
lines[line_idx] += new_content  # Should use +=, not =
print(f"Line {line_idx} after: '{lines[line_idx]}'")
    \end{lstlisting}

    \item \textbf{Verify Final Join}
    \begin{lstlisting}
print(f"Lines array: {lines}")
content = "\n".join(lines)
print(f"Joined content: '{content}'")
print(f"Content length: {len(content)}")
    \end{lstlisting}
\end{enumerate}

\textbf{Common Mistakes:}
\begin{itemize}
    \item Forgetting to sort events by timestamp
    \item Using \texttt{=} instead of \texttt{+=} for append
    \item Off-by-one error with 1-indexed vs 0-indexed
    \item Not handling case-insensitive event names
    \item Creating extra empty lines with improper split/join
\end{itemize}
\end{tipbox}

\newpage

\section{Follow-Up Questions \& Variations}

\subsection{Expected Follow-Ups}

\begin{enumerate}
    \item \textbf{What if events can arrive significantly out of order?}
    \begin{itemize}
        \item Current solution handles this with sorting
        \item For streaming: use priority queue or buffering window
        \item Trade-off: latency vs correctness
    \end{itemize}

    \item \textbf{How would you handle millions of events?}
    \begin{itemize}
        \item Batch processing
        \item Periodic snapshots + incremental updates
        \item Event sourcing pattern
        \item Compaction/aggregation of old events
    \end{itemize}

    \item \textbf{What about concurrent editing by multiple users?}
    \begin{itemize}
        \item Operational Transform (OT)
        \item Conflict-free Replicated Data Types (CRDTs)
        \item Last-write-wins with timestamps
        \item Use event\_id as tiebreaker
    \end{itemize}

    \item \textbf{How would you optimize for very large documents?}
    \begin{itemize}
        \item Rope data structure instead of list
        \item Lazy loading of content
        \item Chunk-based storage
        \item Only process visible viewport
    \end{itemize}

    \item \textbf{What if we add more event types?}
    \begin{itemize}
        \item \texttt{insert}: Insert at character position within line
        \item \texttt{delete\_range}: Delete specific line range
        \item \texttt{replace}: Replace content at line
        \item \texttt{format}: Apply formatting (bold, italic)
    \end{itemize}
\end{enumerate}

\subsection{Variation 1: Insert at Character Position}

\textbf{New Event Type:}
\begin{lstlisting}
{
    "event_name": "insert",
    "payload": {
        "newContent": "text",
        "startLine": 2,
        "position": 5  # Character position in line (0-indexed)
    },
    "timestamp": 100
}
\end{lstlisting}

\textbf{Implementation:}
\begin{lstlisting}
elif event_name == "insert":
    new_content = payload["newContent"]
    start_line = payload["startLine"]
    position = payload["position"]

    line_idx = start_line - 1
    while len(lines) <= line_idx:
        lines.append("")

    line = lines[line_idx]
    # Insert at character position
    lines[line_idx] = line[:position] + new_content + line[position:]
\end{lstlisting}

\subsection{Variation 2: Delete Specific Lines}

\textbf{New Event Type:}
\begin{lstlisting}
{
    "event_name": "delete_range",
    "payload": {
        "startLine": 2,
        "endLine": 4    # Inclusive
    },
    "timestamp": 100
}
\end{lstlisting}

\textbf{Implementation:}
\begin{lstlisting}
elif event_name == "delete_range":
    start_line = payload["startLine"]
    end_line = payload["endLine"]

    start_idx = start_line - 1
    end_idx = end_line - 1

    # Delete lines in range
    if start_idx < len(lines):
        del lines[start_idx:min(end_idx + 1, len(lines))]
\end{lstlisting}

\subsection{Variation 3: Replace Line Content}

\textbf{New Event Type:}
\begin{lstlisting}
{
    "event_name": "replace",
    "payload": {
        "newContent": "completely new text",
        "startLine": 3
    },
    "timestamp": 100
}
\end{lstlisting}

\textbf{Implementation:}
\begin{lstlisting}
elif event_name == "replace":
    new_content = payload["newContent"]
    start_line = payload["startLine"]

    line_idx = start_line - 1
    while len(lines) <= line_idx:
        lines.append("")

    # Replace entire line (use = instead of +=)
    lines[line_idx] = new_content
\end{lstlisting}

\newpage

\section{Alternative Implementations}

\subsection{Object-Oriented Approach (Python)}

\begin{lstlisting}
class DocumentProcessor:
    """OOP approach for document event processing."""

    def __init__(self, document):
        self.document = document.copy()
        self.lines = self._init_lines()

    def _init_lines(self):
        """Initialize lines from document content."""
        content = self.document.get("content", "")
        return content.split("\n") if content else []

    def process_events(self, events):
        """Process all events and return updated document."""
        if not events:
            return self.document

        sorted_events = sorted(events, key=lambda e: e["timestamp"])

        for event in sorted_events:
            self._process_event(event)

        return self._finalize()

    def _process_event(self, event):
        """Process single event based on type."""
        event_name = event["event_name"].lower()

        if event_name == "append":
            self._handle_append(event)
        elif event_name == "delete":
            self._handle_delete(event)
        # Easy to add more event types here

    def _handle_append(self, event):
        """Handle append event."""
        payload = event["payload"]
        new_content = payload["newContent"]
        start_line = payload["startLine"]

        line_idx = start_line - 1

        # Extend lines if needed
        while len(self.lines) <= line_idx:
            self.lines.append("")

        self.lines[line_idx] += new_content
        self.document["lastUpdated"] = event["timestamp"]

    def _handle_delete(self, event):
        """Handle delete event."""
        self.lines = []
        self.document["lastUpdated"] = event["timestamp"]

    def _finalize(self):
        """Finalize and return document."""
        self.document["content"] = "\n".join(self.lines)
        return self.document


# Usage
def execute(events, document):
    processor = DocumentProcessor(document)
    return processor.process_events(events)
\end{lstlisting}

\newpage

\section{System Design Discussion}

\subsection{Real-World ClickUp Architecture}

In production, ClickUp likely uses:

\begin{enumerate}
    \item \textbf{Event Store / Event Sourcing}
    \begin{itemize}
        \item Kafka or similar for event streaming
        \item Permanent event log (source of truth)
        \item Can replay events to rebuild state
        \item Enables time-travel debugging
    \end{itemize}

    \item \textbf{CRDT (Conflict-free Replicated Data Types)}
    \begin{itemize}
        \item Handle concurrent edits from multiple users
        \item Eventual consistency without conflicts
        \item Examples: Yjs, Automerge
        \item Used by: Figma, Notion, Google Docs
    \end{itemize}

    \item \textbf{Operational Transform (OT)}
    \begin{itemize}
        \item Transform conflicting operations
        \item Maintain causal ordering
        \item More complex but deterministic
        \item Used by: Google Docs originally
    \end{itemize}

    \item \textbf{Snapshot + Delta Pattern}
    \begin{itemize}
        \item Store periodic snapshots
        \item Apply only recent events
        \item Faster recovery and queries
        \item Reduce memory usage
    \end{itemize}

    \item \textbf{WebSocket for Real-time Sync}
    \begin{itemize}
        \item Push events to all connected clients
        \item Low latency updates
        \item Handle reconnection gracefully
    \end{itemize}
\end{enumerate}

\subsection{Scalability Challenges}

\begin{itemize}
    \item \textbf{Large Documents}: Millions of characters, thousands of lines
    \item \textbf{High Event Rate}: Hundreds of events per second per document
    \item \textbf{Many Concurrent Users}: 10+ people editing simultaneously
    \item \textbf{Offline Support}: Sync when reconnected, handle conflicts
    \item \textbf{Undo/Redo}: Maintain operation history efficiently
    \item \textbf{Performance}: Sub-second response time even for large docs
\end{itemize}

\subsection{Data Structures for Large Documents}

\begin{itemize}
    \item \textbf{Rope}: Tree-based string for efficient insertions/deletions
    \item \textbf{Gap Buffer}: Used by Emacs, good for cursor-based editing
    \item \textbf{Piece Table}: Used by VS Code, great for undo/redo
    \item \textbf{CRDT Text}: Yjs uses linked list with tombstones
\end{itemize}

\newpage

\section{Interview Execution Strategy}

\subsection{Time Allocation (60 minutes)}

\begin{itemize}
    \item \textbf{5 min}: Clarify requirements, ask questions, confirm understanding
    \item \textbf{3 min}: Discuss approach, mention data structures, complexity
    \item \textbf{2 min}: Write function signature and comments
    \item \textbf{25 min}: Implement core solution (clean, working code)
    \item \textbf{10 min}: Write and run tests (catch bugs early!)
    \item \textbf{5 min}: Add error handling and edge cases
    \item \textbf{10 min}: Follow-up questions, optimizations, discussion
\end{itemize}

\subsection{Before You Code}

\begin{tipbox}
\textbf{The First 5 Minutes Are Critical!}

\begin{enumerate}
    \item \textbf{Clarify Requirements}
    \begin{itemize}
        \item "Should lastUpdated use the event timestamp or increment?"
        \item "What happens with invalid line numbers?"
        \item "Should I validate event structure?"
    \end{itemize}

    \item \textbf{Confirm Examples}
    \begin{itemize}
        \item Walk through Example 1 verbally
        \item Confirm expected output matches your understanding
        \item Note any inconsistencies in examples
    \end{itemize}

    \item \textbf{Discuss Approach}
    \begin{itemize}
        \item "I'll sort events by timestamp first..."
        \item "I'll use a list for lines for O(1) indexing..."
        \item "Time complexity will be O(n log n) for sorting..."
    \end{itemize}

    \item \textbf{Mention Edge Cases}
    \begin{itemize}
        \item "I'll need to handle out-of-order events..."
        \item "Case-insensitive event names..."
        \item "Multiple appends to same line..."
    \end{itemize}
\end{enumerate}

\textbf{This shows you're thinking critically and builds trust!}
\end{tipbox}

\subsection{While Coding}

\begin{enumerate}
    \item \textbf{Think Out Loud}
    \begin{itemize}
        \item "Now I'll sort the events by timestamp..."
        \item "Converting to 0-indexed here because Python lists..."
        \item "Using += here to append, not replace..."
    \end{itemize}

    \item \textbf{Write Clean Code}
    \begin{itemize}
        \item Descriptive variable names: \texttt{line\_idx}, not \texttt{i}
        \item Add comments for non-obvious logic
        \item Consistent spacing and formatting
    \end{itemize}

    \item \textbf{Handle Errors Gracefully}
    \begin{itemize}
        \item Use \texttt{.get()} for optional dictionary keys
        \item Check for None/empty before processing
        \item Validate inputs if time permits
    \end{itemize}

    \item \textbf{Ask If Stuck}
    \begin{itemize}
        \item "I'm debating between X and Y, which would you prefer?"
        \item "Should I prioritize robustness or simplicity here?"
        \item Don't sit in silence - communicate!
    \end{itemize}
\end{enumerate}

\subsection{After Coding}

\begin{enumerate}
    \item \textbf{Test Immediately}
    \begin{itemize}
        \item Run provided examples first
        \item Test edge cases (empty, out-of-order, same line)
        \item Fix any bugs found
    \end{itemize}

    \item \textbf{Walk Through Code}
    \begin{itemize}
        \item Explain your solution at high level
        \item Point out key design decisions
        \item Mention trade-offs considered
    \end{itemize}

    \item \textbf{Discuss Improvements}
    \begin{itemize}
        \item "For production, I'd add validation..."
        \item "Could optimize with rope data structure..."
        \item "Would need CRDT for real-time collaboration..."
    \end{itemize}

    \item \textbf{Handle Follow-Ups}
    \begin{itemize}
        \item Be ready for variations (insert, delete range)
        \item Explain how to extend solution
        \item Discuss system design implications
    \end{itemize}
\end{enumerate}

\newpage

\section{Communication Checklist}

\subsection{Before Interview}

\begin{itemize}
    \item[$\square$] Practiced core solution multiple times (can code in 20-25 min)
    \item[$\square$] Memorized critical edge cases
    \item[$\square$] Tested with all provided examples
    \item[$\square$] Understand time/space complexity
    \item[$\square$] Reviewed follow-up variations
    \item[$\square$] Comfortable with Python
    \item[$\square$] Practiced explaining thought process out loud
    \item[$\square$] Prepared clarifying questions to ask
\end{itemize}

\subsection{During Interview - Execution}

\begin{itemize}
    \item[$\square$] Asked clarifying questions upfront
    \item[$\square$] Confirmed understanding of examples
    \item[$\square$] Explained approach before coding
    \item[$\square$] Thought out loud while implementing
    \item[$\square$] Handled edge cases explicitly
    \item[$\square$] Wrote clean, readable code
    \item[$\square$] Tested code with examples
    \item[$\square$] Discussed complexity analysis
    \item[$\square$] Proposed optimizations
    \item[$\square$] Asked intelligent follow-up questions
\end{itemize}

\subsection{During Interview - Communication}

\begin{itemize}
    \item[$\square$] Maintained conversational tone
    \item[$\square$] Explained reasoning for decisions
    \item[$\square$] Asked for feedback/hints when stuck
    \item[$\square$] Admitted when unsure (don't fake it)
    \item[$\square$] Showed enthusiasm and engagement
    \item[$\square$] Treated interviewer as collaborator
\end{itemize}

\newpage

\section{Quick Reference Card}

\subsection{Key Points to Remember}

\begin{enumerate}
    \item \textbf{ALWAYS sort events by timestamp first!}
    \item \textbf{Use list for lines} (not string manipulation)
    \item \textbf{Lines are 1-indexed} in problem, 0-indexed in Python
    \item \textbf{Case-insensitive event names} - use \texttt{.lower()}
    \item \textbf{APPEND to line} with \texttt{+=}, DON'T REPLACE with \texttt{=}
    \item \textbf{Fill gaps} with empty strings when extending
    \item \textbf{Update lastUpdated} to latest event timestamp
    \item \textbf{Return a copy} - don't mutate input document
\end{enumerate}

\subsection{Common Mistakes to Avoid}

\begin{itemize}
    \item X Forgetting to sort events
    \item X Not handling case-insensitive event names
    \item X Using \texttt{=} instead of \texttt{+=} for append (replaces instead of appends!)
    \item X Off-by-one errors with 1-indexed vs 0-indexed
    \item X Not handling empty events or missing content
    \item X Modifying input document directly
    \item X Not testing edge cases
\end{itemize}

\subsection{Python Quick Reference}

\begin{lstlisting}
# Safe dictionary access
content = document.get("content", "")  # Default empty string
payload = event.get("payload", {})     # Default empty dict

# Case-insensitive comparison
event_name = event["event_name"].lower()

# List operations
lines = []
lines.append("new")           # Add to end
lines[idx] += "text"          # Append to existing
while len(lines) <= idx:      # Extend with gaps
    lines.append("")

# String operations
lines = content.split("\n")   # Split into list
content = "\n".join(lines)    # Join back to string

# Sorting
sorted_events = sorted(events, key=lambda e: e["timestamp"])

# List comprehension
valid = [e for e in events if e.get("timestamp") is not None]
\end{lstlisting}

\newpage

\section{Final Preparation Checklist}

\subsection{Technical Readiness}

\begin{itemize}
    \item[$\square$] Can implement solution in under 25 minutes
    \item[$\square$] All 12+ test cases pass without bugs
    \item[$\square$] Understand why each edge case matters
    \item[$\square$] Can explain time/space complexity
    \item[$\square$] Know how to extend for new event types
    \item[$\square$] Comfortable with alternative approaches (OOP, JS)
\end{itemize}

\subsection{Interview Skills}

\begin{itemize}
    \item[$\square$] Practiced asking clarifying questions
    \item[$\square$] Can explain approach before coding
    \item[$\square$] Comfortable thinking out loud
    \item[$\square$] Know how to debug when tests fail
    \item[$\square$] Can discuss system design implications
    \item[$\square$] Ready for follow-up variations
\end{itemize}

\subsection{Day Before Interview}

\begin{itemize}
    \item[$\square$] Do one final practice run (timed, 30 min)
    \item[$\square$] Review edge cases one more time
    \item[$\square$] Read through this guide's key sections
    \item[$\square$] Prepare 2-3 questions to ask interviewer
    \item[$\square$] Get good sleep - fresh mind is critical!
\end{itemize}

\subsection{Interview Day}

\begin{itemize}
    \item[$\square$] Test internet connection and mic/camera
    \item[$\square$] Have this guide open for reference (if allowed)
    \item[$\square$] Water nearby, comfortable environment
    \item[$\square$] Positive mindset - you've got this!
\end{itemize}

\newpage

\section{PART 2: Search Architecture Deep Dive Prep}

\subsection{Interview Format}

\textbf{Session:} Search Architecture Deep Dive (60 minutes)

\textbf{Focus Areas:}
\begin{itemize}
    \item Multi-tenanted Search (ClickUp has workspaces - critical!)
    \item Search Ranking (BM25, field boosting, relevance)
    \item ElasticSearch/OpenSearch architecture
    \item Vector Search (semantic search for tasks/docs)
    \item Query DSL and practical search scenarios
\end{itemize}

\textbf{Your Knowledge Level:}
\begin{itemize}
    \item ✓ Strong: Vector search concepts, high-level architecture, autocomplete
    \item ⚠ Need refresh: BM25 details, field boosting, relevance scoring
    \item ✗ Gap: Multi-tenancy strategies, cross-tenant data leaks, Query DSL
\end{itemize}

\newpage

\section{Priority 1: Multi-Tenanted Search (MUST KNOW)}

\subsection{The Problem}

ClickUp has multiple workspaces (tenants). When User A in Workspace 1 searches "project update", they should ONLY see results from their workspace, never from Workspace 2.

\textbf{Critical Requirements:}
\begin{itemize}
    \item \textbf{Data Isolation}: Tenant A can't see Tenant B's data
    \item \textbf{Performance}: Don't slow down search for isolation
    \item \textbf{Scalability}: Support millions of tenants
    \item \textbf{Cost}: Balance resources vs isolation
\end{itemize}

\subsection{Strategy 1: Index-Per-Tenant}

\textbf{Concept:} Each tenant gets their own dedicated index.

\begin{verbatim}
workspace_123_tasks  # Workspace 123's task index
workspace_456_tasks  # Workspace 456's task index
workspace_789_tasks  # Workspace 789's task index
\end{verbatim}

\textbf{Pros:}
\begin{itemize}
    \item ✓ Perfect isolation (impossible to leak data)
    \item ✓ Easy to delete tenant data (drop the index)
    \item ✓ Can tune per-tenant settings
    \item ✓ Clear billing/resource tracking
\end{itemize}

\textbf{Cons:}
\begin{itemize}
    \item ✗ ES has limits (1000s of indices max)
    \item ✗ Overhead per index (shards, mappings)
    \item ✗ Can't search across tenants (admin features)
    \item ✗ Cluster management complexity
\end{itemize}

\textbf{When to use:}
\begin{itemize}
    \item Small number of large tenants (B2B SaaS)
    \item Strict compliance requirements
    \item Tenants need custom settings
\end{itemize}

\subsection{Strategy 2: Shared Index with Filtering}

\textbf{Concept:} All tenants share one index, filter by tenant\_id field.

\begin{verbatim}
tasks_index:
{
  "task_id": "t123",
  "workspace_id": "ws_123",  # <-- CRITICAL field
  "title": "Project update",
  "description": "..."
}
\end{verbatim}

\textbf{Query Pattern:}
\begin{lstlisting}[language=Java]
{
  "query": {
    "bool": {
      "must": [
        {"match": {"title": "project update"}}
      ],
      "filter": [
        {"term": {"workspace_id": "ws_123"}}  // ALWAYS filter!
      ]
    }
  }
}
\end{lstlisting}

\textbf{Pros:}
\begin{itemize}
    \item ✓ Scales to millions of tenants
    \item ✓ Lower overhead (fewer indices)
    \item ✓ Can search across tenants (admin)
    \item ✓ Easier cluster management
\end{itemize}

\textbf{Cons:}
\begin{itemize}
    \item ✗ Data leak risk if filter missed
    \item ✗ Noisy neighbor problem
    \item ✗ Can't delete tenant data easily
    \item ✗ Query complexity increases
\end{itemize}

\textbf{When to use:}
\begin{itemize}
    \item Many small-medium tenants (ClickUp likely uses this)
    \item Need cross-tenant analytics
    \item Cost optimization critical
\end{itemize}

\subsection{Strategy 3: Hybrid (Index Pools)}

\textbf{Concept:} Group tenants into pools, multiple tenants per index.

\begin{verbatim}
pool_1_tasks   # Tenants 1-1000
pool_2_tasks   # Tenants 1001-2000
pool_3_tasks   # Tenants 2001-3000
\end{verbatim}

Balance between isolation and scalability.

\subsection{Preventing Cross-Tenant Data Leaks}

\begin{warningbox}
\textbf{CRITICAL: How to Prevent Leaks}

\begin{enumerate}
    \item \textbf{ALWAYS Filter at Query Time}
    \begin{lstlisting}[language=Java]
// WRONG - can leak data!
{"query": {"match": {"title": "update"}}}

// CORRECT - always filter
{
  "query": {
    "bool": {
      "must": [{"match": {"title": "update"}}],
      "filter": [{"term": {"workspace_id": "ws_123"}}]
    }
  }
}
    \end{lstlisting}

    \item \textbf{Middleware Enforcement}
    \begin{lstlisting}
class SearchService:
    def search(self, user, query):
        # ALWAYS inject workspace_id from auth context
        workspace_id = user.workspace_id

        # Force filter into query
        query["query"]["bool"]["filter"].append({
            "term": {"workspace_id": workspace_id}
        })

        return es.search(query)
    \end{lstlisting}

    \item \textbf{Index-Time Validation}
    \begin{itemize}
        \item Verify workspace\_id exists in every document
        \item Reject documents without workspace\_id
        \item Validate workspace\_id format
    \end{itemize}

    \item \textbf{Security Audits}
    \begin{itemize}
        \item Log all search queries
        \item Alert on queries without tenant filter
        \item Periodic security reviews
        \item Test with penetration testing
    \end{itemize}

    \item \textbf{Query Templates}
    \begin{itemize}
        \item Use parameterized query templates
        \item Never build queries with string concatenation
        \item workspace\_id as required parameter
    \end{itemize}
\end{enumerate}
\end{warningbox}

\subsection{ClickUp-Specific Multi-Tenancy}

\textbf{ClickUp's Architecture (likely):}
\begin{itemize}
    \item Shared index with workspace\_id filtering
    \item Tasks, docs, comments in same index (tagged by type)
    \item High-traffic workspaces might get dedicated indices
    \item Filter: \texttt{workspace\_id AND user\_permissions}
\end{itemize}

\textbf{Interview Question:} "How would you design search for ClickUp with 1M+ workspaces?"

\textbf{Your Answer:}
\begin{enumerate}
    \item Start with shared index (scales to millions)
    \item Every document: workspace\_id (indexed, not analyzed)
    \item Middleware ALWAYS injects workspace filter
    \item Large workspaces (>10K users) → dedicated indices
    \item Route queries to correct index pool
    \item Security: audit logs, query templates, validation
\end{enumerate}

\subsection{Performance Optimizations (HIGH IMPACT)}

\textbf{1. Routing by workspace\_id}

\textbf{Problem:} Query searches ALL shards even if workspace data is on one shard.

\textbf{Solution:} Route documents and queries by workspace\_id

\begin{lstlisting}
# Index with routing
PUT /tasks/_doc/task_123?routing=ws_456

# Query with routing (searches only relevant shard!)
GET /tasks/_search?routing=ws_456

# Benefit: If workspace has 1M docs across 10 shards,
# query searches 1 shard instead of all 10!
# 10x performance improvement!
\end{lstlisting}

\textbf{2. Hierarchical Filtering (ClickUp Realistic)}

Beyond just workspace\_id, ClickUp has complex permissions:

\begin{lstlisting}
# Document structure
{
  "task_id": "t123",
  "workspace_id": "ws_456",
  "accessible_by_user_ids": ["user_1", "user_2", "user_3"],
  "accessible_by_team_ids": ["team_10", "team_15"],
  "is_public": false
}

# Query: workspace AND (user OR team OR public)
{
  "query": {
    "bool": {
      "must": [{"match": {"title": "project"}}],
      "filter": [
        {"term": {"workspace_id": "ws_456"}},
        {
          "bool": {
            "should": [
              {"term": {"accessible_by_user_ids": "user_1"}},
              {"terms": {"accessible_by_team_ids": ["team_10", "team_15"]}},
              {"term": {"is_public": true}}
            ],
            "minimum_should_match": 1
          }
        }
      ]
    }
  }
}
\end{lstlisting}

\textbf{3. Caching Strategy}

\begin{itemize}
    \item \textbf{Query Cache}: ES caches entire query results
    \begin{itemize}
        \item Best for: Repeated identical queries
        \item Example: "status:open" query cached per workspace
    \end{itemize}

    \item \textbf{Filter Cache}: Caches filter bit sets
    \begin{itemize}
        \item \texttt{workspace\_id} filters cached (high reuse!)
        \item \texttt{status}, \texttt{priority} filters cached
        \item Filters in "filter" context are cached (not "must")
    \end{itemize}

    \item \textbf{Request Cache}: Caches aggregations
    \begin{itemize}
        \item Dashboard: "How many tasks per status?"
        \item Cached at shard level
    \end{itemize}
\end{itemize}

\textbf{4. Rate Limiting \& Noisy Neighbors}

\begin{lstlisting}
# Prevent one workspace from overwhelming cluster
class SearchService:
    def search(self, user, query):
        workspace_id = user.workspace_id

        # Rate limit per workspace (e.g., 100 QPS)
        if not rate_limiter.allow(workspace_id, max_qps=100):
            raise RateLimitError("Too many requests")

        # Inject mandatory filter
        query = inject_workspace_filter(query, workspace_id)
        return es.search(query)
\end{lstlisting}

\textbf{5. Tier-Based Architecture}

\begin{verbatim}
Small workspaces (< 10K docs):
  → shared_index_pool_1 (10K workspaces)

Medium workspaces (10K-100K docs):
  → shared_index_pool_2 (1K workspaces)

Large enterprise (> 100K docs):
  → dedicated_index_enterprise_A
  → dedicated_index_enterprise_B

Benefits:
- Large customers get guaranteed performance
- Small customers share resources efficiently
- Can migrate between tiers as workspace grows
\end{verbatim}

\textbf{Interview Impact:} Mentioning routing + caching shows deep understanding!

\newpage

\section{Priority 2: Relevance Scoring \& Ranking}

\subsection{BM25 Algorithm (ElasticSearch Default)}

\textbf{BM25 Formula (you should know this):}

\begin{verbatim}
score(D,Q) = Σ IDF(q_i) × [f(q_i,D) × (k1 + 1)] /
                          [f(q_i,D) + k1 × (1 - b + b × |D|/avgdl)]

Where:
- D = document
- Q = query
- q_i = query term i
- f(q_i,D) = frequency of term q_i in document D
- |D| = length of document D (in words)
- avgdl = average document length in collection
- k1 = term frequency saturation parameter (default: 1.2)
- b = length normalization parameter (default: 0.75)
- IDF(q_i) = inverse document frequency of term q_i
\end{verbatim}

\textbf{Key Concepts:}

\begin{enumerate}
    \item \textbf{TF (Term Frequency)}: More occurrences = higher score
    \begin{itemize}
        \item But with diminishing returns (saturation)
        \item "project project project" isn't 3x better than "project"
    \end{itemize}

    \item \textbf{IDF (Inverse Document Frequency)}: Rare terms matter more
    \begin{itemize}
        \item "the" appears everywhere → low IDF → low weight
        \item "kubernetes" is rare → high IDF → high weight
    \end{itemize}

    \item \textbf{Document Length Normalization}: Longer docs penalized
    \begin{itemize}
        \item Short doc with "project" beats long doc with same term
        \item Parameter b controls strength (0=off, 1=full)
    \end{itemize}

    \item \textbf{Saturation (k1)}: Diminishing returns on term frequency
    \begin{itemize}
        \item 2nd occurrence matters less than 1st
        \item 10th occurrence barely matters
    \end{itemize}
\end{enumerate}

\textbf{BM25 vs TF-IDF:}
\begin{itemize}
    \item TF-IDF: Linear relationship (2x frequency = 2x score)
    \item BM25: Logarithmic (2x frequency $\approx$ 1.2x score)
    \item BM25 handles document length better
    \item BM25 is more robust to keyword stuffing
\end{itemize}

\subsection{Field Boosting}

\textbf{Problem:} Title matches should rank higher than body matches.

\textbf{ElasticSearch Syntax:}
\begin{lstlisting}[language=Java]
{
  "query": {
    "multi_match": {
      "query": "project update",
      "fields": [
        "title^3",        // 3x boost
        "description^1",  // 1x (normal)
        "comments^0.5"    // 0.5x (less important)
      ]
    }
  }
}
\end{lstlisting}

\textbf{How Boosting Works:}
\begin{itemize}
    \item Base score calculated per field
    \item Final score = title\_score × 3 + desc\_score × 1 + comments\_score × 0.5
    \item Title match contributes 3x more than description
\end{itemize}

\textbf{ClickUp Example:}
\begin{lstlisting}[language=Java]
{
  "query": {
    "multi_match": {
      "query": "project update",
      "fields": [
        "task_name^5",     // Task name most important
        "task_description^2",
        "comments^1",
        "attachments.filename^1.5"
      ]
    }
  }
}
\end{lstlisting}

\subsection{Custom Scoring}

\textbf{Beyond BM25:} Incorporate business logic.

\textbf{Function Score Query:}
\begin{lstlisting}[language=Java]
{
  "query": {
    "function_score": {
      "query": {"match": {"title": "project"}},
      "functions": [
        {
          "filter": {"term": {"priority": "high"}},
          "weight": 2  // Boost high priority tasks
        },
        {
          "gauss": {  // Decay based on date
            "created_date": {
              "origin": "now",
              "scale": "30d",
              "decay": 0.5
            }
          }
        },
        {
          "field_value_factor": {
            "field": "likes_count",  // Popular tasks rank higher
            "modifier": "log1p"
          }
        }
      ],
      "boost_mode": "multiply"
    }
  }
}
\end{lstlisting}

\textbf{ClickUp Ranking Factors:}
\begin{enumerate}
    \item Text relevance (BM25)
    \item Task priority (high/medium/low)
    \item Recency (newer tasks slightly boosted)
    \item User activity (tasks user interacted with)
    \item Completion status (open > completed)
    \item Assignee (user's own tasks boosted)
\end{enumerate}

\subsection{Interview Question: Rank "project update"}

\textbf{Scenario:} User searches "project update" in ClickUp.

\textbf{Your Answer:}
\begin{enumerate}
    \item \textbf{Base Score}: BM25 on task name, description
    \item \textbf{Field Boosts}: task\_name^5, description^2
    \item \textbf{Priority}: High priority tasks +50\% boost
    \item \textbf{Recency}: Exponential decay over 90 days
    \item \textbf{Status}: Open tasks +30\%, completed -20\%
    \item \textbf{Personalization}: User's assigned tasks +40\%
    \item \textbf{Workspace Activity}: Recently viewed/edited +20\%
\end{enumerate}

\begin{lstlisting}[language=Java]
{
  "query": {
    "function_score": {
      "query": {
        "bool": {
          "must": [{
            "multi_match": {
              "query": "project update",
              "fields": ["task_name^5", "description^2"]
            }
          }],
          "filter": [{"term": {"workspace_id": "ws_123"}}]
        }
      },
      "functions": [
        {"filter": {"term": {"priority": "high"}}, "weight": 1.5},
        {"filter": {"term": {"status": "open"}}, "weight": 1.3},
        {"filter": {"term": {"assignee_id": "user_abc"}}, "weight": 1.4},
        {"gauss": {"updated_at": {"origin": "now", "scale": "90d"}}}
      ]
    }
  }
}
\end{lstlisting}

\newpage

\section{Priority 3: Query DSL Essentials}

\subsection{Core Query Types}

\textbf{1. Match Query} (Full-text search)
\begin{lstlisting}[language=Java]
{"query": {"match": {"title": "project update"}}}
// Analyzes text, finds "project" OR "update"
\end{lstlisting}

\textbf{2. Term Query} (Exact match, no analysis)
\begin{lstlisting}[language=Java]
{"query": {"term": {"status": "open"}}}
// Exact match, case-sensitive, used for IDs, enums
\end{lstlisting}

\textbf{3. Bool Query} (Combine multiple conditions)
\begin{lstlisting}[language=Java]
{
  "query": {
    "bool": {
      "must": [{"match": {"title": "project"}}],     // AND
      "should": [{"match": {"tags": "urgent"}}],     // OR (boost)
      "must_not": [{"term": {"status": "deleted"}}], // NOT
      "filter": [{"term": {"workspace_id": "ws_1"}}] // AND (no score)
    }
  }
}
\end{lstlisting}

\textbf{4. Multi-Match} (Search across multiple fields)
\begin{lstlisting}[language=Java]
{
  "query": {
    "multi_match": {
      "query": "update",
      "fields": ["title^3", "description"]
    }
  }
}
\end{lstlisting}

\textbf{5. Range Query}
\begin{lstlisting}[language=Java]
{
  "query": {
    "range": {
      "created_date": {
        "gte": "2024-01-01",
        "lte": "2024-12-31"
      }
    }
  }
}
\end{lstlisting}

\subsection{Filter vs Query}

\textbf{Query Context:} Affects relevance score
\begin{lstlisting}[language=Java]
"must": [{"match": {"title": "project"}}]  // Scores results
\end{lstlisting}

\textbf{Filter Context:} Binary yes/no, cached, faster
\begin{lstlisting}[language=Java]
"filter": [{"term": {"workspace_id": "ws_1"}}]  // No scoring
\end{lstlisting}

\textbf{Rule:} Use filter for exact matches (status, IDs, dates). Use query for text search.

\subsection{ClickUp Search Query Example}

\begin{lstlisting}[language=Java]
{
  "query": {
    "bool": {
      "must": [
        {
          "multi_match": {
            "query": "project update",
            "fields": ["task_name^5", "description^2", "comments"]
          }
        }
      ],
      "filter": [
        {"term": {"workspace_id": "ws_123"}},
        {"terms": {"status": ["open", "in_progress"]}},
        {"range": {"created_date": {"gte": "now-1y"}}}
      ],
      "should": [
        {"term": {"assignee_id": "user_abc"}},  // Boost user's tasks
        {"term": {"priority": "high"}}
      ],
      "must_not": [
        {"term": {"archived": true}}
      ]
    }
  },
  "sort": [
    {"_score": "desc"},
    {"updated_at": "desc"}
  ],
  "size": 20
}
\end{lstlisting}

\newpage

\section{Priority 4: Vector Search Refresher}

\subsection{When to Use Vector Search}

\textbf{Keyword Search (BM25):} "kubernetes deployment"
\begin{itemize}
    \item Finds exact keyword matches
    \item Fast, efficient, proven
    \item Fails on synonyms: "k8s deployment" won't match
\end{itemize}

\textbf{Vector Search (Semantic):} "container orchestration setup"
\begin{itemize}
    \item Finds semantically similar content
    \item Matches even without exact keywords
    \item Slower, more expensive
\end{itemize}

\textbf{ClickUp Use Case:} User searches "meeting notes" → also finds "discussion summary", "call recap"

\subsection{Hybrid Search (Best Practice)}

\begin{lstlisting}[language=Java]
{
  "query": {
    "bool": {
      "should": [
        {
          "multi_match": {
            "query": "project update",
            "fields": ["title^3", "description"]
          }
        },
        {
          "knn": {
            "field": "description_vector",
            "query_vector": [0.23, -0.45, ...],  // 768 dims
            "k": 10,
            "num_candidates": 100
          }
        }
      ],
      "filter": [{"term": {"workspace_id": "ws_123"}}]
    }
  }
}
\end{lstlisting}

\textbf{Combines:}
\begin{itemize}
    \item BM25 for exact keyword matches
    \item Vector search for semantic similarity
    \item Best of both worlds
\end{itemize}

\subsection{Vector Search Trade-offs}

\textbf{Pros:}
\begin{itemize}
    \item Handles synonyms, paraphrases
    \item Language-agnostic (multilingual)
    \item Understands intent, context
\end{itemize}

\textbf{Cons:}
\begin{itemize}
    \item 10-100x more storage (768-dimensional vectors)
    \item Slower (ANN search still expensive)
    \item Needs pre-trained embeddings model
    \item Black box (hard to debug)
\end{itemize}

\textbf{ClickUp Strategy:}
\begin{itemize}
    \item Primary: BM25 (fast, accurate for exact matches)
    \item Fallback: Vector search if BM25 returns few results
    \item Hybrid: Combine scores for complex queries
\end{itemize}

\newpage

\section{ElasticSearch vs OpenSearch}

\subsection{Key Differences}

\begin{itemize}
    \item \textbf{Licensing}: ES went proprietary (2021), OpenSearch is Apache 2.0
    \item \textbf{Vendor}: ES by Elastic, OpenSearch by AWS + community
    \item \textbf{Features}: ES has newer features (ELSER, security). OpenSearch catching up.
    \item \textbf{Cloud}: AWS only supports OpenSearch, not ES
    \item \textbf{Compatibility}: OpenSearch maintains ES API compatibility (mostly)
    \item \textbf{Cost}: OpenSearch free, ES requires license for some features
\end{itemize}

\textbf{For ClickUp:} Likely using OpenSearch (AWS-hosted) or self-managed ES cluster.

\subsection{When to Choose Which}

\textbf{Choose OpenSearch if:}
\begin{itemize}
    \item Using AWS (native integration)
    \item Want open-source without licensing concerns
    \item Cost-sensitive
    \item Need community control
\end{itemize}

\textbf{Choose ElasticSearch if:}
\begin{itemize}
    \item Need latest Elastic features (ML, security)
    \item Want official Elastic Cloud
    \item Existing Elastic ecosystem
    \item Enterprise support critical
\end{itemize}

\newpage

\section{2-Hour Prep: Quick Reference Cheat Sheet}

\subsection{Must-Know Talking Points (Memorize These)}

\begin{tcolorbox}[colback=yellow!10!white,colframe=orange!75!black,title=\textbf{TOP 3 THINGS TO SAY}]
\begin{enumerate}
    \item \textbf{Multi-tenancy:} "For ClickUp's scale with millions of workspaces, I'd use a shared index with workspace\_id filtering enforced at the middleware layer, never trusting the client. Large enterprise customers (>100K docs) would get dedicated indices for performance guarantees."

    \item \textbf{Performance:} "Key optimization is routing by workspace\_id, which means queries search only 1 shard instead of all 10 - that's a 10x improvement. Combined with filter caching for workspace\_id and rate limiting per tenant."

    \item \textbf{Ranking:} "I'd start with BM25 for text relevance, boost important fields like task\_name\textasciicircum 5, and layer on business logic using function\_score for priority, recency with exponential decay, and personalization."
\end{enumerate}
\end{tcolorbox}

\subsection{The 5-Minute Mental Model}

\textbf{Multi-Tenancy Architecture:}
\begin{verbatim}
Strategy: Shared Index + Filtering (scales to millions)

Document:
{
  "workspace_id": "ws_123",  ← ALWAYS FILTER ON THIS
  "accessible_by_user_ids": [...],
  "accessible_by_team_ids": [...],
  "task_name": "...",
  ...
}

Query:
ALWAYS: bool → filter → term: workspace_id
ALWAYS: Inject server-side (never trust client!)

Performance:
- Route by workspace_id (1 shard vs 10 shards)
- Cache workspace_id filters (high reuse)
- Rate limit per workspace (100 QPS)
\end{verbatim}

\textbf{BM25 Ranking:}
\begin{verbatim}
BM25 = TF × IDF × Length_Normalization

Key params:
- k1 = 1.2 (term frequency saturation)
- b = 0.75 (length normalization strength)

Why BM25 > TF-IDF:
- Logarithmic term frequency (prevents keyword stuffing)
- Better length normalization
- Tunable parameters
\end{verbatim}

\textbf{Field Boosting Pattern:}
\begin{verbatim}
{
  "multi_match": {
    "query": "project update",
    "fields": [
      "task_name^5",        ← Most important
      "description^2",
      "comments^1"
    ]
  }
}

Rule of thumb:
- Title/Name: 5x
- Description: 2x
- Comments/Body: 1x
- Metadata: 0.5x
\end{verbatim}

\subsection{Interview Question Templates}

\textbf{Q: "Design search for ClickUp with 1M+ workspaces"}

\textbf{A:}
\begin{enumerate}
    \item Architecture: Shared index with workspace\_id field
    \item Security: Middleware enforces filter (never trust client)
    \item Performance: Route by workspace\_id, cache filters
    \item Tiering: Large workspaces (>100K docs) → dedicated indices
    \item Ranking: BM25 + field boosting + business logic
\end{enumerate}

\textbf{Q: "How do you prevent cross-tenant data leaks?"}

\textbf{A:}
\begin{enumerate}
    \item workspace\_id from auth token (not query param)
    \item Middleware ALWAYS injects filter before ES
    \item Validate all docs have workspace\_id at index time
    \item Security audits: alert on queries without filter
    \item Testing: penetration tests, chaos testing
\end{enumerate}

\textbf{Q: "How do you rank 'project update' results?"}

\textbf{A:}
\begin{enumerate}
    \item Base: BM25 text relevance (ES default)
    \item Fields: Boost task\_name\textasciicircum 5, description\textasciicircum 2
    \item Business: function\_score for priority, status, assignee
    \item Recency: Exponential decay over 90 days
    \item Personalization: Boost user's tasks, team tasks
\end{enumerate}

\subsection{Production Architecture: Gateway Pattern}

\textbf{Key Insight:} Clients NEVER access ES directly - use a gateway/facade!

\begin{verbatim}
Client Apps --> Search Gateway --> Tiered ES Backends
                     |                    |
                     |              ┌─────┴─────┐
                     |              |           |
                  Enforces:    Enterprise  Premium  Shared
                  - Auth         Clusters   Indices  Index
                  - Filters
                  - Routing
                  - Rate limits
\end{verbatim}

\textbf{Why Gateway Pattern?}
\begin{itemize}
    \item \textbf{Security}: Single enforcement point, no direct ES access
    \item \textbf{Flexibility}: Swap backends, A/B test, gradual migrations
    \item \textbf{Control}: Rate limiting, query validation, audit logging
    \item \textbf{Tiering}: Route large clients to dedicated resources
\end{itemize}

\textbf{Gateway Code Pattern:}
\begin{lstlisting}
class SearchGateway:
    def search(self, user, query_text):
        # 1. Authenticate
        if not user.is_authenticated():
            raise Unauthorized()

        # 2. Get user's workspaces
        workspaces = self.get_user_workspaces(user.id)

        # 3. Rate limit per workspace
        if not self.rate_limiter.check(workspace_id):
            raise RateLimitExceeded()

        # 4. Build query with ENFORCED filters
        query = {
            "query": {
                "bool": {
                    "must": [{"match": {"title": query_text}}],
                    "filter": [
                        {"term": {"workspace_id": workspace_id}},
                        {"terms": {"accessible_by": [user.id]}}
                    ]
                }
            }
        }

        # 5. Route to correct backend tier
        backend = self.route_to_backend(workspace_id)

        # 6. Execute and audit log
        results = backend.search(query)
        self.audit_log(user.id, workspace_id, query_text)

        return results

    def route_to_backend(self, workspace_id):
        tier = self.tenant_registry.get_tier(workspace_id)

        if tier == "enterprise":
            return self.enterprise_cluster
        elif tier == "premium":
            return self.premium_index
        else:
            return self.shared_index
\end{lstlisting}

\textbf{Tiered Backend Strategy:}
\begin{itemize}
    \item \textbf{Enterprise (Top 0.1\%)}: Dedicated ES cluster, 1000 QPS, 99.99\% SLA
    \item \textbf{Premium (Top 5\%)}: Dedicated index in shared cluster, 100 QPS
    \item \textbf{Shared (94.9\%)}: Multi-tenant filtered index, 10 QPS
\end{itemize}

\textbf{When to Mention:}
\begin{itemize}
    \item Interviewer asks: "How would you design this in production?"
    \item Discussing security: "In production, I'd add a gateway so clients never access ES directly"
    \item Discussing scale: "Gateway routes large tenants to dedicated resources"
\end{itemize}

\subsection{Code Snippets You Should Know}

\textbf{1. Multi-tenancy Filter (CRITICAL):}
\begin{lstlisting}
def search(user, query_text):
    workspace_id = user.workspace_id  # From auth

    query = {
        "query": {
            "bool": {
                "must": [{"match": {"title": query_text}}],
                "filter": [{"term": {"workspace_id": workspace_id}}]
            }
        }
    }
    return es.search(index="tasks", body=query)
\end{lstlisting}

\textbf{2. Field Boosting:}
\begin{lstlisting}[language=Java]
{
  "query": {
    "multi_match": {
      "query": "project update",
      "fields": ["task_name^5", "description^2", "comments^1"]
    }
  }
}
\end{lstlisting}

\textbf{3. Function Score (Priority + Recency):}
\begin{lstlisting}[language=Java]
{
  "query": {
    "function_score": {
      "query": {"match": {"title": "project"}},
      "functions": [
        {
          "filter": {"term": {"priority": "high"}},
          "weight": 2
        },
        {
          "gauss": {
            "created_date": {
              "origin": "now",
              "scale": "30d",
              "decay": 0.5
            }
          }
        }
      ],
      "boost_mode": "multiply"
    }
  }
}
\end{lstlisting}

\subsection{Key Numbers to Remember}

\begin{itemize}
    \item \textbf{BM25 k1}: 1.2 (term frequency saturation)
    \item \textbf{BM25 b}: 0.75 (length normalization)
    \item \textbf{Field boost ratios}: 5:2:1 (title:description:body)
    \item \textbf{Recency decay}: 90 days (exponential)
    \item \textbf{Dedicated index threshold}: >100K docs per tenant
    \item \textbf{Rate limit}: 100 QPS per workspace
    \item \textbf{ES index limit}: ~1000s of indices (why shared index scales)
\end{itemize}

\subsection{Common Mistakes to Avoid}

\begin{enumerate}
    \item ❌ "Use one index per user" → Doesn't scale to millions
    \item ❌ Forgetting workspace\_id filter → Data leak!
    \item ❌ Client-side filtering → Security vulnerability!
    \item ❌ Not mentioning routing → Missed performance win
    \item ❌ Saying "TF-IDF" instead of "BM25" → Shows outdated knowledge
    \item ❌ Only BM25, no business logic → Not production-ready
\end{enumerate}

\subsection{If You Blank on Details}

\textbf{Safe fallback phrases:}
\begin{itemize}
    \item "I'd need to check the exact ES API syntax, but the concept is..."
    \item "In production, I'd validate this with load testing to tune parameters..."
    \item "I'd start with the default (BM25/k1=1.2) and A/B test adjustments..."
    \item "Security is critical here - I'd enforce filters server-side and add audit logging..."
\end{itemize}

\textbf{When to say you don't know:}
\begin{itemize}
    \item "I haven't tuned BM25 parameters in production, but I understand the k1 and b parameters control saturation and length normalization."
    \item "I'm familiar with the concept of vector search, but I'd want to measure precision/recall before choosing between semantic and keyword search."
\end{itemize}

\subsection{Last-Minute Review (15 mins before)}

\textbf{Read these 3 sections:}
\begin{enumerate}
    \item Multi-Tenancy: Strategy 2 (Shared Index) + Security (lines 1558-1682)
    \item Performance Optimizations: Routing + Caching (lines 1706-1822)
    \item Interview Scenarios: Scenario 1 \& 2 (lines 2126-2220)
\end{enumerate}

\textbf{Mental checklist before you start:}
\begin{itemize}
    \item[$\square$] I can explain shared index + workspace\_id filtering
    \item[$\square$] I know BM25 is better than TF-IDF (logarithmic term frequency)
    \item[$\square$] I can write a multi\_match query with field boosting
    \item[$\square$] I understand routing improves performance (1 shard vs 10)
    \item[$\square$] I know security: server-side filter enforcement is critical
\end{itemize}

\newpage

\vspace{2cm}

\noindent\rule{\textwidth}{0.4pt}

\vspace{0.5cm}

\noindent\textbf{\Large You Are Ready!}

\vspace{0.5cm}

\noindent You've prepared thoroughly. You know the solution inside-out. You understand the edge cases. You can handle follow-ups. Now trust your preparation and show them what you can do!

\vspace{0.5cm}

\noindent\textbf{Remember:}
\begin{itemize}
    \item The interviewer wants you to succeed
    \item They're evaluating how you think, not just coding speed
    \item Communication matters as much as the solution
    \item It's okay to ask questions - that's smart!
    \item One bug doesn't fail you - recovery matters
\end{itemize}

\vspace{0.5cm}

\noindent\textbf{\Large Good luck with your ClickUp interview!}

\end{document}
