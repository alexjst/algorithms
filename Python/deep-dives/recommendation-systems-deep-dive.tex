\documentclass[10pt]{article}
\usepackage[margin=0.75in]{geometry}
\usepackage{amsmath,amsthm,amsfonts,amssymb}
\usepackage{color,graphicx}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{enumitem}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{lightgray!20},
    basicstyle=\ttfamily\small,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}

\lstset{style=mystyle}

\title{\textbf{Recommendation Systems Deep Dive} \\ \large Expert-Level Guide for Staff/Principal Interviews}
\author{}
\date{}

\begin{document}
\maketitle

\section*{Overview}

This guide provides **expert-level** coverage of recommendation systems for engineers with search background who need to refresh on recommendation-specific concepts. It covers modern deep learning approaches, production architecture patterns, and interview preparation for Staff/Principal roles.

\textbf{Key Differences: Search vs Recommendations}
\begin{itemize}
\item \textbf{Search}: User expresses intent via query → match documents
\item \textbf{Recommendations}: Predict user preferences without explicit query → discovery
\item \textbf{Search}: Relevance is primary objective
\item \textbf{Recommendations}: Balance relevance, diversity, novelty, serendipity
\item \textbf{Search}: Query-dependent features dominate
\item \textbf{Recommendations}: User history \& collaborative signals dominate
\end{itemize}

\section{Modern Recommendation Architecture}

\subsection{Industry Standard: Three-Stage Funnel}

\textbf{Stage 1: Candidate Generation (Retrieval)}
\begin{itemize}
\item \textbf{Goal}: Reduce 100M items → 10K candidates (99.99\% reduction)
\item \textbf{Latency budget}: 10-50ms
\item \textbf{Methods}: Multiple retrieval sources, each contributing candidates
\end{itemize}

\textbf{Stage 2: Ranking}
\begin{itemize}
\item \textbf{Goal}: Score 10K candidates → Top 500 items
\item \textbf{Latency budget}: 50-100ms
\item \textbf{Model}: Complex ML model (neural network, gradient boosting)
\end{itemize}

\textbf{Stage 3: Re-ranking}
\begin{itemize}
\item \textbf{Goal}: Final ordering with diversity, business rules
\item \textbf{Latency budget}: 10-20ms
\item \textbf{Methods}: Rule-based, lightweight model, or optimization
\end{itemize}

\subsection{Candidate Generation (Retrieval) in Depth}

Unlike search (where query provides strong signal), recommendations need **multiple retrieval sources**:

\textbf{1. Collaborative Filtering Retrievals}

\textbf{A. User-Based CF}
\begin{verbatim}
Given user u:
1. Find K similar users {u1, u2, ..., uK}
2. Recommend items those users liked
3. Similarity: Cosine(user_vector_u, user_vector_v)
\end{verbatim}

\textbf{B. Item-Based CF (More Stable)}
\begin{verbatim}
Given user u who liked items {i1, i2, ..., im}:
1. For each liked item ij, find K similar items
2. Aggregate and rank candidate items
3. Similarity: Cosine(item_vector_i, item_vector_j)
\end{verbatim}

\textbf{Why Item-Based > User-Based in Production:}
\begin{itemize}
\item Item similarities change slower (precompute daily)
\item User preferences change constantly (require real-time)
\item Fewer items than users (smaller index)
\item Better cold start for new users
\end{itemize}

\textbf{C. Matrix Factorization (SVD, ALS)}

\textbf{Problem formulation:}
\begin{align*}
R &\approx U \times V^T \\
\text{where } & R \in \mathbb{R}^{n \times m} \text{ (user-item interaction matrix)} \\
& U \in \mathbb{R}^{n \times k} \text{ (user embeddings)} \\
& V \in \mathbb{R}^{m \times k} \text{ (item embeddings)}
\end{align*}

\textbf{Loss function (explicit feedback):}
\begin{equation}
\min_{U,V} \sum_{(u,i) \in \text{observed}} (r_{ui} - u_u^T v_i)^2 + \lambda (||u_u||^2 + ||v_i||^2)
\end{equation}

\textbf{Loss function (implicit feedback - BPR):}
\begin{equation}
\min_{U,V} \sum_{(u,i,j)} -\log \sigma(u_u^T(v_i - v_j)) + \lambda (||u_u||^2 + ||v_i||^2 + ||v_j||^2)
\end{equation}
where $i$ is positive item, $j$ is negative item for user $u$

\textbf{Training (ALS - Alternating Least Squares):}
\begin{lstlisting}[language=Python]
# Alternate between fixing U and optimizing V, and vice versa
for epoch in range(num_epochs):
    # Fix U, optimize V
    for item in items:
        users_who_liked = get_users(item)
        # Closed-form solution for item embedding
        V[item] = solve(U[users_who_liked], R[:, item])

    # Fix V, optimize U
    for user in users:
        items_user_liked = get_items(user)
        # Closed-form solution for user embedding
        U[user] = solve(V[items_user_liked], R[user, :])
\end{lstlisting}

\textbf{At serving time:}
\begin{lstlisting}[language=Python]
# Retrieve candidates using ANN search
user_embedding = U[user_id]  # (k,)
candidates = ann_index.search(user_embedding, top_k=1000)
# Returns item IDs with highest dot product scores
\end{lstlisting}

\textbf{2. Deep Learning Retrievals}

\textbf{A. Two-Tower Neural Network (Google YouTube DNN)}

\textbf{Architecture:}
\begin{verbatim}
User Features               Item Features
(age, gender,               (title, category,
 watch history,              upload time,
 search history)             tags, popularity)
     ↓                            ↓
User Tower (DNN)            Item Tower (DNN)
(3-4 layers, ReLU)          (3-4 layers, ReLU)
     ↓                            ↓
User Embedding              Item Embedding
   (128-dim)                   (128-dim)
         ↓                   ↓
           Dot Product → Score
\end{verbatim}

\textbf{Training:}
\begin{lstlisting}[language=Python]
import torch
import torch.nn as nn

class TwoTowerModel(nn.Module):
    def __init__(self, user_features_dim, item_features_dim, embedding_dim):
        super().__init__()

        # User tower
        self.user_tower = nn.Sequential(
            nn.Linear(user_features_dim, 256),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, embedding_dim)
        )

        # Item tower
        self.item_tower = nn.Sequential(
            nn.Linear(item_features_dim, 256),
            nn.ReLU(),
            nn.BatchNorm1d(256),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, embedding_dim)
        )

    def forward(self, user_features, item_features):
        user_emb = self.user_tower(user_features)  # (batch, embedding_dim)
        item_emb = self.item_tower(item_features)  # (batch, embedding_dim)

        # Normalize embeddings (important for dot product!)
        user_emb = F.normalize(user_emb, p=2, dim=1)
        item_emb = F.normalize(item_emb, p=2, dim=1)

        # Dot product score
        score = torch.sum(user_emb * item_emb, dim=1)
        return score, user_emb, item_emb

# Training with sampled softmax
def sampled_softmax_loss(model, user_features, pos_item_features,
                         neg_item_features_list):
    """
    user_features: (batch, user_feat_dim)
    pos_item_features: (batch, item_feat_dim) - positive items
    neg_item_features_list: list of (batch, item_feat_dim) - negative samples
    """
    # Positive score
    pos_score, user_emb, pos_item_emb = model(user_features, pos_item_features)

    # Negative scores
    neg_scores = []
    for neg_item_features in neg_item_features_list:
        neg_score, _, _ = model(user_features, neg_item_features)
        neg_scores.append(neg_score)

    # Concatenate: [pos_score, neg_score1, neg_score2, ...]
    all_scores = torch.stack([pos_score] + neg_scores, dim=1)  # (batch, 1+num_neg)

    # Labels: positive is at index 0
    labels = torch.zeros(all_scores.size(0), dtype=torch.long).to(all_scores.device)

    # Softmax cross-entropy
    loss = F.cross_entropy(all_scores, labels)
    return loss
\end{lstlisting}

\textbf{Negative Sampling Strategies:}
\begin{enumerate}
\item \textbf{Random sampling}: Sample uniformly from item catalog
\item \textbf{Popularity-based}: Sample proportional to $\text{popularity}^{0.75}$ (word2vec trick)
\item \textbf{Hard negative mining}: Sample items user didn't click but were shown
\item \textbf{Batch negative}: Use other positives in batch as negatives (efficient!)
\end{enumerate}

\textbf{Batch Negative Example:}
\begin{lstlisting}[language=Python]
# In-batch negatives (used by Pinterest, Alibaba)
def batch_negative_loss(user_emb, item_emb):
    """
    user_emb: (batch_size, dim)
    item_emb: (batch_size, dim) - each is positive for corresponding user
    """
    # Score matrix: (batch_size, batch_size)
    scores = torch.matmul(user_emb, item_emb.T)

    # Diagonal elements are positive pairs
    # Off-diagonal are negatives
    labels = torch.arange(scores.size(0)).to(scores.device)

    loss = F.cross_entropy(scores, labels)
    return loss
\end{lstlisting}

\textbf{At Serving Time:}
\begin{lstlisting}[language=Python]
# Build ANN index for all items (offline, daily)
item_embeddings = []
for item_batch in all_items:
    item_features = get_item_features(item_batch)
    _, item_emb = item_tower(item_features)
    item_embeddings.append(item_emb)

item_embeddings = torch.cat(item_embeddings)  # (num_items, embedding_dim)

# Store in FAISS
import faiss
index = faiss.IndexFlatIP(embedding_dim)  # Inner product (dot product)
index.add(item_embeddings.cpu().numpy())

# At serving time (real-time)
user_features = get_user_features(user_id)
user_emb, _ = user_tower(user_features)

# ANN search
D, I = index.search(user_emb.cpu().numpy(), k=1000)
# I contains item IDs, D contains scores
\end{lstlisting}

\textbf{B. Sequential Models (GRU4Rec, SASRec, BERT4Rec)}

\textbf{Use case}: Capture sequential patterns in user behavior

\textbf{GRU4Rec (Session-based):}
\begin{lstlisting}[language=Python]
class GRU4Rec(nn.Module):
    def __init__(self, num_items, embedding_dim, hidden_dim):
        super().__init__()
        self.item_embedding = nn.Embedding(num_items, embedding_dim)
        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, num_items)

    def forward(self, item_sequence):
        """
        item_sequence: (batch, seq_len) - item IDs in session
        """
        # Embed items
        embedded = self.item_embedding(item_sequence)  # (batch, seq_len, emb_dim)

        # GRU
        output, hidden = self.gru(embedded)  # output: (batch, seq_len, hidden_dim)

        # Predict next item from last timestep
        logits = self.fc(output[:, -1, :])  # (batch, num_items)

        return logits

# Training
model = GRU4Rec(num_items=100000, embedding_dim=128, hidden_dim=256)

for session in sessions:
    # session = [item1, item2, item3, item4, item5]
    input_seq = session[:-1]  # [item1, item2, item3, item4]
    target = session[-1]       # item5

    logits = model(input_seq)
    loss = F.cross_entropy(logits, target)
    loss.backward()
    optimizer.step()
\end{lstlisting}

\textbf{SASRec (Self-Attention for Sequential Recommendation):}
\begin{lstlisting}[language=Python]
class SASRec(nn.Module):
    def __init__(self, num_items, embedding_dim, num_heads, num_layers):
        super().__init__()
        self.item_embedding = nn.Embedding(num_items, embedding_dim)
        self.pos_embedding = nn.Embedding(200, embedding_dim)  # Max seq length

        # Transformer encoder
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embedding_dim,
            nhead=num_heads,
            dim_feedforward=embedding_dim*4
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)

        self.fc = nn.Linear(embedding_dim, num_items)

    def forward(self, item_sequence):
        """
        item_sequence: (batch, seq_len)
        """
        batch_size, seq_len = item_sequence.size()

        # Item embeddings
        item_emb = self.item_embedding(item_sequence)  # (batch, seq_len, dim)

        # Positional embeddings
        positions = torch.arange(seq_len).unsqueeze(0).expand(batch_size, -1).to(item_sequence.device)
        pos_emb = self.pos_embedding(positions)  # (batch, seq_len, dim)

        # Combine
        x = item_emb + pos_emb

        # Transformer (with causal masking for autoregressive)
        mask = nn.Transformer.generate_square_subsequent_mask(seq_len).to(item_sequence.device)
        x = x.transpose(0, 1)  # (seq_len, batch, dim)
        output = self.transformer(x, mask=mask)
        output = output.transpose(0, 1)  # (batch, seq_len, dim)

        # Predict next item
        logits = self.fc(output[:, -1, :])  # (batch, num_items)

        return logits
\end{lstlisting}

\textbf{3. Content-Based Retrieval}

Good for cold start (new items):
\begin{lstlisting}[language=Python]
# For new item (no collaborative signal yet)
# 1. Extract content features
item_features = {
    'title_embedding': bert_encode(item.title),  # (768,)
    'category': item.category,
    'tags': item.tags,
    'description_embedding': bert_encode(item.description)
}

# 2. Find similar items in catalog
similar_items = faiss_index.search(item_features['title_embedding'], k=100)

# 3. Retrieve users who liked those similar items
candidate_users = get_users_who_liked(similar_items)
\end{lstlisting}

\textbf{4. Graph-Based Retrieval (Pinterest, Alibaba)}

\textbf{Item2Vec / Node2Vec:}
\begin{lstlisting}[language=Python]
# Build item-item co-occurrence graph
# Edge weight = # of users who interacted with both items

import networkx as nx
from node2vec import Node2Vec

# Create graph
G = nx.Graph()
for user in users:
    items = user.interacted_items
    # Add edges between co-occurring items
    for i in range(len(items)):
        for j in range(i+1, len(items)):
            if G.has_edge(items[i], items[j]):
                G[items[i]][items[j]]['weight'] += 1
            else:
                G.add_edge(items[i], items[j], weight=1)

# Node2Vec random walks
node2vec = Node2Vec(G, dimensions=128, walk_length=80, num_walks=10)
model = node2vec.fit(window=10, min_count=1)

# Get item embeddings
item_embedding = model.wv[item_id]

# Retrieve similar items
similar_items = model.wv.most_similar(item_id, topn=100)
\end{lstlisting}

\textbf{5. Blending Multiple Retrieval Sources}

\begin{lstlisting}[language=Python]
def retrieve_candidates(user_id, top_k=1000):
    """Blend multiple retrieval sources"""

    # Source 1: Collaborative filtering (user-based)
    cf_candidates = cf_retrieval(user_id, top_k=300)

    # Source 2: Two-tower model
    two_tower_candidates = two_tower_retrieval(user_id, top_k=300)

    # Source 3: Sequential model (if user has recent session)
    if has_recent_session(user_id):
        seq_candidates = sequential_retrieval(user_id, top_k=200)
    else:
        seq_candidates = []

    # Source 4: Trending items (exploration)
    trending_candidates = get_trending_items(top_k=100)

    # Source 5: Content-based (for diversity)
    content_candidates = content_based_retrieval(user_id, top_k=100)

    # Combine and deduplicate
    all_candidates = deduplicate([
        cf_candidates,
        two_tower_candidates,
        seq_candidates,
        trending_candidates,
        content_candidates
    ])

    # Return top K by combined score
    return rank_and_select(all_candidates, top_k=top_k)
\end{lstlisting}

\subsection{Ranking Stage}

\textbf{Goal}: Precisely score candidates using rich features \& complex models

\textbf{Modern Ranking Architectures:}

\textbf{1. Deep \& Wide (Google Play)}

\textbf{Architecture:}
\begin{verbatim}
Wide Component                    Deep Component
(Cross features,                 (Embeddings + DNN,
 manual features)                 learned features)
      ↓                                  ↓
  Linear Model                       Deep NN
      ↓                                  ↓
         Combined (concatenate) → Sigmoid → CTR
\end{verbatim}

\textbf{Implementation:}
\begin{lstlisting}[language=Python]
class DeepAndWide(nn.Module):
    def __init__(self, wide_dim, deep_dim, embedding_dims):
        super().__init__()

        # Wide component (linear)
        self.wide = nn.Linear(wide_dim, 1)

        # Deep component (DNN)
        # Embeddings for categorical features
        self.embeddings = nn.ModuleList([
            nn.Embedding(num_categories, emb_dim)
            for num_categories, emb_dim in embedding_dims
        ])

        # Deep network
        total_emb_dim = sum([emb_dim for _, emb_dim in embedding_dims])
        self.deep = nn.Sequential(
            nn.Linear(total_emb_dim + deep_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1)
        )

    def forward(self, wide_features, categorical_features, deep_features):
        # Wide path
        wide_out = self.wide(wide_features)  # (batch, 1)

        # Embed categorical features
        embeddings = [emb(cat_feat) for emb, cat_feat in
                     zip(self.embeddings, categorical_features)]
        embeddings = torch.cat(embeddings, dim=1)  # (batch, total_emb_dim)

        # Deep path
        deep_input = torch.cat([embeddings, deep_features], dim=1)
        deep_out = self.deep(deep_input)  # (batch, 1)

        # Combine
        logits = wide_out + deep_out
        output = torch.sigmoid(logits)

        return output
\end{lstlisting}

\textbf{2. DeepFM (Huawei, Criteo)}

\textbf{Key innovation}: Replace manual wide features with FM (Factorization Machine)

\textbf{Architecture:}
\begin{verbatim}
Features → Embeddings → FM Component (2-way interactions)
                      ↓
                      DNN Component (high-order interactions)
                      ↓
                Combined → Sigmoid → CTR
\end{verbatim}

\textbf{FM Component:}
\begin{equation}
y_{FM} = w_0 + \sum_{i=1}^n w_i x_i + \sum_{i=1}^n \sum_{j=i+1}^n \langle v_i, v_j \rangle x_i x_j
\end{equation}

\textbf{Implementation:}
\begin{lstlisting}[language=Python]
class DeepFM(nn.Module):
    def __init__(self, feature_sizes, embedding_dim=16):
        super().__init__()

        # Embeddings (shared between FM and DNN)
        self.embeddings = nn.ModuleList([
            nn.Embedding(feat_size, embedding_dim)
            for feat_size in feature_sizes
        ])

        # FM: first-order weights
        self.fm_first_order = nn.ModuleList([
            nn.Embedding(feat_size, 1)
            for feat_size in feature_sizes
        ])

        # DNN
        total_embedding_dim = len(feature_sizes) * embedding_dim
        self.dnn = nn.Sequential(
            nn.Linear(total_embedding_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 1)
        )

        self.bias = nn.Parameter(torch.zeros(1))

    def forward(self, categorical_features):
        """
        categorical_features: list of (batch,) tensors, one per feature field
        """
        # Get embeddings
        embeddings = [emb(feat) for emb, feat in
                     zip(self.embeddings, categorical_features)]
        # Each: (batch, embedding_dim)

        # FM first-order
        first_order = sum([
            emb(feat).squeeze(1) for emb, feat in
            zip(self.fm_first_order, categorical_features)
        ])  # (batch,)

        # FM second-order (pairwise interactions)
        # Efficient computation: sum of squares - square of sum
        sum_of_embeddings = sum(embeddings)  # (batch, embedding_dim)
        square_of_sum = torch.pow(sum_of_embeddings, 2)  # (batch, embedding_dim)

        sum_of_squares = sum([torch.pow(emb, 2) for emb in embeddings])  # (batch, embedding_dim)

        second_order = 0.5 * torch.sum(square_of_sum - sum_of_squares, dim=1)  # (batch,)

        # DNN
        dnn_input = torch.cat(embeddings, dim=1)  # (batch, total_embedding_dim)
        dnn_out = self.dnn(dnn_input).squeeze(1)  # (batch,)

        # Combine
        logits = self.bias + first_order + second_order + dnn_out
        output = torch.sigmoid(logits)

        return output
\end{lstlisting}

\textbf{3. Multi-Task Learning (YouTube, Facebook)}

\textbf{Motivation}: Optimize for multiple objectives simultaneously

\textbf{Example objectives:}
\begin{itemize}
\item Click probability (engagement)
\item Watch time (quality engagement)
\item Like probability
\item Share probability
\item Conversion probability (purchase, subscribe)
\end{itemize}

\textbf{Architecture:}
\begin{lstlisting}[language=Python]
class MultiTaskRanking(nn.Module):
    def __init__(self, input_dim):
        super().__init__()

        # Shared bottom layers
        self.shared = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 128),
            nn.ReLU()
        )

        # Task-specific towers
        self.click_tower = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )

        self.watch_time_tower = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1)  # Regression, no sigmoid
        )

        self.like_tower = nn.Sequential(
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )

    def forward(self, features):
        shared_repr = self.shared(features)  # (batch, 128)

        p_click = self.click_tower(shared_repr)  # (batch, 1)
        watch_time = self.watch_time_tower(shared_repr)  # (batch, 1)
        p_like = self.like_tower(shared_repr)  # (batch, 1)

        return {
            'p_click': p_click,
            'watch_time': watch_time,
            'p_like': p_like
        }

# Training
def multi_task_loss(outputs, labels, weights={'click': 1.0, 'watch_time': 0.5, 'like': 0.3}):
    loss_click = F.binary_cross_entropy(outputs['p_click'], labels['click'])
    loss_watch_time = F.mse_loss(outputs['watch_time'], labels['watch_time'])
    loss_like = F.binary_cross_entropy(outputs['p_like'], labels['like'])

    total_loss = (weights['click'] * loss_click +
                  weights['watch_time'] * loss_watch_time +
                  weights['like'] * loss_like)

    return total_loss

# Final ranking score
def compute_score(outputs):
    # Weighted combination
    score = (0.4 * outputs['p_click'] +
             0.4 * outputs['watch_time'] / 300.0 +  # Normalize watch time
             0.2 * outputs['p_like'])
    return score
\end{lstlisting}

\subsection{Re-ranking Stage}

\textbf{Goals:}
\begin{enumerate}
\item \textbf{Diversity}: Avoid showing too many similar items
\item \textbf{Freshness}: Boost recent content
\item \textbf{Exploration}: Include some random items for discovery
\item \textbf{Business rules}: Position constraints, deduplication
\end{enumerate}

\textbf{1. Maximal Marginal Relevance (MMR)}

\textbf{Formula:}
\begin{equation}
\text{MMR} = \arg\max_{d_i \in R \setminus S} [\lambda \cdot \text{Relevance}(d_i) - (1-\lambda) \cdot \max_{d_j \in S} \text{Similarity}(d_i, d_j)]
\end{equation}

\textbf{Implementation:}
\begin{lstlisting}[language=Python]
def mmr_rerank(ranked_items, scores, similarity_matrix, lambda_param=0.7, top_k=50):
    """
    ranked_items: List of item IDs sorted by score
    scores: Dict mapping item_id -> score
    similarity_matrix: item_i, item_j -> similarity [0, 1]
    lambda_param: Trade-off between relevance and diversity
    """
    selected = []
    remaining = ranked_items.copy()

    # First item: highest score
    first_item = remaining.pop(0)
    selected.append(first_item)

    while len(selected) < top_k and remaining:
        mmr_scores = []

        for item in remaining:
            # Relevance component
            relevance = scores[item]

            # Diversity component (similarity to already selected)
            max_similarity = max([
                similarity_matrix[item][selected_item]
                for selected_item in selected
            ])

            # MMR score
            mmr = lambda_param * relevance - (1 - lambda_param) * max_similarity
            mmr_scores.append((item, mmr))

        # Select item with highest MMR
        best_item = max(mmr_scores, key=lambda x: x[1])[0]
        selected.append(best_item)
        remaining.remove(best_item)

    return selected
\end{lstlisting}

\textbf{2. Determinantal Point Process (DPP)}

Used by Google, Twitter for diversity-aware ranking.

\textbf{Idea}: Model subset selection with diversity kernel

\begin{lstlisting}[language=Python]
import numpy as np
from dppy.finite_dpps import FiniteDPP

def dpp_rerank(items, scores, similarity_matrix, k=50):
    """
    Use DPP to select diverse subset
    """
    n = len(items)

    # Build DPP kernel: L = quality * diversity
    # Quality diagonal matrix
    quality = np.diag([scores[item] for item in items])

    # Diversity matrix (inverse of similarity)
    diversity = 1 - similarity_matrix

    # DPP kernel
    L = quality @ diversity @ quality

    # Sample from DPP
    dpp = FiniteDPP('likelihood', **{'L': L})
    dpp.sample_exact()

    selected_indices = dpp.list_of_samples[-1]
    selected_items = [items[i] for i in selected_indices[:k]]

    return selected_items
\end{lstlisting}

\textbf{3. Exploration (Multi-Armed Bandits)}

\textbf{Epsilon-Greedy:}
\begin{lstlisting}[language=Python]
def epsilon_greedy_rerank(ranked_items, epsilon=0.1, top_k=50):
    """
    With probability epsilon, inject random items
    """
    import random

    result = []
    for i in range(top_k):
        if random.random() < epsilon:
            # Explore: random item from catalog
            result.append(random.choice(item_catalog))
        else:
            # Exploit: use ranked item
            if i < len(ranked_items):
                result.append(ranked_items[i])

    return result
\end{lstlisting}

\textbf{Thompson Sampling (Contextual Bandit):}
\begin{lstlisting}[language=Python]
# Used by Netflix for personalized thumbnails
class ThompsonSampling:
    def __init__(self, num_items):
        # Beta distribution parameters for each item
        self.alpha = np.ones(num_items)  # Successes (clicks)
        self.beta = np.ones(num_items)   # Failures (no clicks)

    def select_item(self, candidate_items):
        # Sample from Beta distribution for each candidate
        samples = [
            np.random.beta(self.alpha[item], self.beta[item])
            for item in candidate_items
        ]

        # Select item with highest sample
        best_idx = np.argmax(samples)
        return candidate_items[best_idx]

    def update(self, item, clicked):
        # Update distribution based on feedback
        if clicked:
            self.alpha[item] += 1
        else:
            self.beta[item] += 1
\end{lstlisting}

\subsection{Multi-Objective Optimization}

At Staff/Principal level, you're expected to balance multiple business objectives, not just maximize a single metric.

\textbf{The Real-World Problem:}

Recommendation systems have \textbf{conflicting objectives}:
\begin{itemize}
\item \textbf{User engagement}: Click-through rate, watch time
\item \textbf{Business revenue}: Ad clicks, subscription conversions
\item \textbf{Content diversity}: Don't show only viral content
\item \textbf{Creator satisfaction}: Fair distribution of impressions
\item \textbf{Platform health}: Reduce misinformation, toxic content
\end{itemize}

\textbf{Naive approach}: Single weighted objective $L = w_1 \cdot \text{CTR} + w_2 \cdot \text{Revenue}$

\textbf{Problem}: Hard to tune weights, doesn't show trade-offs

\textbf{1. Pareto Frontier \& Scalarization}

\textbf{Pareto optimality}: A solution where you can't improve one objective without hurting another

\textbf{Weighted sum approach:}
\begin{equation}
L = \sum_{i=1}^{n} w_i \cdot f_i(x), \quad \sum w_i = 1
\end{equation}

\textbf{Implementation:}
\begin{lstlisting}[language=Python]
import numpy as np

class MultiObjectiveRanker:
    def __init__(self, objectives, weights):
        """
        objectives: List of objective functions (higher is better)
        weights: List of weights for each objective
        """
        self.objectives = objectives
        self.weights = np.array(weights)
        assert abs(self.weights.sum() - 1.0) < 1e-6  # Must sum to 1

    def score(self, item, user_context):
        """Compute weighted score for item"""
        scores = np.array([
            obj(item, user_context) for obj in self.objectives
        ])
        # Normalize to [0, 1] before combining
        scores_normalized = (scores - scores.min()) / (scores.max() - scores.min() + 1e-8)
        return np.dot(self.weights, scores_normalized)

    def rank(self, items, user_context):
        """Rank items by multi-objective score"""
        scores = [(item, self.score(item, user_context)) for item in items]
        ranked = sorted(scores, key=lambda x: x[1], reverse=True)
        return [item for item, score in ranked]

# Example: Balance CTR and revenue
def ctr_objective(item, user_context):
    # Predict click probability
    return model_ctr.predict_proba(item, user_context)

def revenue_objective(item, user_context):
    # Predict expected revenue
    return item.price * model_conversion.predict_proba(item, user_context)

def diversity_objective(item, user_context):
    # Penalize similarity to recently shown items
    recent_items = user_context['recent_items']
    avg_similarity = np.mean([similarity(item, rec) for rec in recent_items])
    return 1 - avg_similarity  # Higher score for diverse items

# Create multi-objective ranker
ranker = MultiObjectiveRanker(
    objectives=[ctr_objective, revenue_objective, diversity_objective],
    weights=[0.5, 0.3, 0.2]  # 50% CTR, 30% revenue, 20% diversity
)

ranked_items = ranker.rank(candidate_items, user_context)
\end{lstlisting}

\textbf{Interview talking point:} "I'd start with simple weighted sum, then A/B test different weight combinations to find Pareto optimal trade-off"

\textbf{2. Pareto Frontier Exploration}

Instead of picking one weight vector, explore the Pareto frontier:

\begin{lstlisting}[language=Python]
def compute_pareto_frontier(items, objectives, num_points=10):
    """
    Compute Pareto frontier by varying weights
    Returns: List of (weights, pareto_optimal_items, objective_values)
    """
    pareto_frontier = []

    # Grid search over weight space
    for alpha in np.linspace(0, 1, num_points):
        weights = [alpha, 1 - alpha]  # For 2 objectives

        # Rank items with these weights
        ranker = MultiObjectiveRanker(objectives, weights)
        ranked = ranker.rank(items, user_context)

        # Evaluate objectives on top-k
        top_k = ranked[:50]
        obj_values = [
            np.mean([obj(item, user_context) for item in top_k])
            for obj in objectives
        ]

        pareto_frontier.append({
            'weights': weights,
            'items': top_k,
            'ctr': obj_values[0],
            'revenue': obj_values[1]
        })

    return pareto_frontier

# Visualize trade-off
import matplotlib.pyplot as plt

frontier = compute_pareto_frontier(items, [ctr_objective, revenue_objective])

ctrs = [p['ctr'] for p in frontier]
revenues = [p['revenue'] for p in frontier]

plt.plot(ctrs, revenues, 'o-')
plt.xlabel('CTR')
plt.ylabel('Revenue')
plt.title('Pareto Frontier: CTR vs Revenue Trade-off')
plt.show()
\end{lstlisting}

\textbf{Use in interviews:} Show you understand trade-offs, not just maximize single metric

\textbf{3. Multi-Task Learning Approach}

Instead of post-hoc weighted combination, train a single model to predict multiple objectives:

\begin{lstlisting}[language=Python]
import torch
import torch.nn as nn

class MultiTaskRankingModel(nn.Module):
    """
    Shared bottom + task-specific towers
    Used by YouTube, Alibaba for multi-objective ranking
    """
    def __init__(self, input_dim, shared_dim, task_dims):
        super(MultiTaskRankingModel, self).__init__()

        # Shared bottom layers (feature extraction)
        self.shared = nn.Sequential(
            nn.Linear(input_dim, 512),
            nn.ReLU(),
            nn.Linear(512, shared_dim),
            nn.ReLU()
        )

        # Task-specific towers
        self.ctr_tower = nn.Sequential(
            nn.Linear(shared_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()  # CTR prediction
        )

        self.revenue_tower = nn.Sequential(
            nn.Linear(shared_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 1)  # Revenue prediction (regression)
        )

        self.engagement_tower = nn.Sequential(
            nn.Linear(shared_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 1)  # Watch time prediction
        )

    def forward(self, x):
        # Shared representation
        shared_repr = self.shared(x)

        # Task-specific predictions
        ctr = self.ctr_tower(shared_repr)
        revenue = self.revenue_tower(shared_repr)
        engagement = self.engagement_tower(shared_repr)

        return {
            'ctr': ctr,
            'revenue': revenue,
            'engagement': engagement
        }

# Training with multi-task loss
def multi_task_loss(predictions, labels, weights):
    """
    predictions: Dict of task predictions
    labels: Dict of task labels
    weights: Dict of task weights
    """
    ctr_loss = nn.BCELoss()(predictions['ctr'], labels['ctr'])
    revenue_loss = nn.MSELoss()(predictions['revenue'], labels['revenue'])
    engagement_loss = nn.MSELoss()(predictions['engagement'], labels['engagement'])

    total_loss = (
        weights['ctr'] * ctr_loss +
        weights['revenue'] * revenue_loss +
        weights['engagement'] * engagement_loss
    )

    return total_loss, {
        'ctr_loss': ctr_loss.item(),
        'revenue_loss': revenue_loss.item(),
        'engagement_loss': engagement_loss.item()
    }

# At serving time, combine predictions
def multi_objective_score(predictions, weights):
    """Combine multi-task predictions into final score"""
    score = (
        weights['ctr'] * predictions['ctr'] +
        weights['revenue'] * predictions['revenue'] / 100 +  # Normalize
        weights['engagement'] * predictions['engagement'] / 3600  # Normalize
    )
    return score
\end{lstlisting}

\textbf{Advantages over weighted sum:}
\begin{itemize}
\item Shared representation learns features useful for all tasks
\item Can adjust weights at serving time without retraining
\item Captures task correlations (positive transfer learning)
\end{itemize}

\textbf{4. Constraint-Based Optimization}

Instead of soft weighting, enforce hard constraints:

\textbf{Example:} Maximize engagement subject to revenue constraint

\begin{equation}
\begin{aligned}
\max_{x} \quad & \text{Engagement}(x) \\
\text{s.t.} \quad & \text{Revenue}(x) \geq R_{\min} \\
& \text{Diversity}(x) \geq D_{\min}
\end{aligned}
\end{equation}

\textbf{Implementation (greedy with constraints):}
\begin{lstlisting}[language=Python]
def constrained_ranking(items, user_context, min_revenue=100, min_diversity=0.5, k=50):
    """
    Maximize engagement subject to revenue and diversity constraints
    """
    ranked = []
    remaining = items.copy()

    current_revenue = 0
    shown_categories = set()

    while len(ranked) < k and remaining:
        # Find best item that satisfies constraints
        best_item = None
        best_engagement = -float('inf')

        for item in remaining:
            # Check revenue constraint
            item_revenue = revenue_objective(item, user_context)
            projected_avg_revenue = (current_revenue + item_revenue) / (len(ranked) + 1)

            if projected_avg_revenue < min_revenue:
                continue  # Violates revenue constraint

            # Check diversity constraint
            shown_categories.add(item.category)
            diversity_score = len(shown_categories) / len(ranked + 1)

            if diversity_score < min_diversity:
                shown_categories.remove(item.category)  # Rollback
                continue  # Violates diversity constraint

            # If constraints satisfied, check engagement
            engagement = engagement_objective(item, user_context)
            if engagement > best_engagement:
                best_engagement = engagement
                best_item = item

        if best_item is None:
            break  # No item satisfies constraints

        ranked.append(best_item)
        remaining.remove(best_item)
        current_revenue += revenue_objective(best_item, user_context)

    return ranked
\end{lstlisting}

\textbf{5. Business Trade-off Discussion (Interview Gold)}

\textbf{Scenario:} "YouTube wants to maximize watch time, but advertisers want more ad impressions"

\textbf{Staff/Principal answer:}
\begin{enumerate}
\item \textbf{Define metrics}:
\begin{itemize}
\item User objective: Total watch time (hours/day/user)
\item Business objective: Ad revenue (\$/user/day)
\item Constraint: User retention rate must not drop
\end{itemize}

\item \textbf{Current state}: Measure baseline (e.g., 30 min watch time, \$0.50 revenue/user)

\item \textbf{Pareto analysis}:
\begin{itemize}
\item Test 5 weight combinations: $(w_{\text{watch}}, w_{\text{revenue}})$ = (1.0, 0.0), (0.7, 0.3), (0.5, 0.5), (0.3, 0.7), (0.0, 1.0)
\item Plot Pareto frontier
\item Identify knee of curve (best trade-off)
\end{itemize}

\item \textbf{A/B test}:
\begin{itemize}
\item Implement top 3 weight configurations
\item Run for 2 weeks with 1\% traffic each
\item Monitor: Watch time, revenue, retention, user complaints
\end{itemize}

\item \textbf{Long-term monitoring}:
\begin{itemize}
\item Track Pareto frontier over time (shifts with user behavior)
\item Quarterly re-optimization
\item Detect if we've moved off optimal frontier
\end{itemize}

\item \textbf{Stakeholder communication}:
\begin{itemize}
\item Show trade-off curve to product team
\item Quantify: "10\% more revenue costs 5\% watch time"
\item Let business decide acceptable trade-off
\end{itemize}
\end{enumerate}

\textbf{Key Interview Talking Points:}

When discussing recommendations, always mention multi-objective optimization:
\begin{enumerate}
\item \textbf{"Let's think about conflicting objectives..."} → Shows strategic thinking
\item \textbf{"I'd compute the Pareto frontier..."} → Demonstrates you understand trade-offs
\item \textbf{"Use multi-task learning with shared bottom..."} → Modern ML approach (YouTube, Alibaba)
\item \textbf{"Monitor multiple metrics, not just optimize one"} → Production mindset
\item \textbf{"Present trade-off curve to stakeholders"} → Staff/Principal communication skill
\end{enumerate}

\textbf{Common Multi-Objective Scenarios:}

\begin{tabular}{|l|l|l|}
\hline
\textbf{System} & \textbf{Objective 1} & \textbf{Objective 2} \\
\hline
YouTube & Watch time & Ad revenue \\
LinkedIn & Engagement & Job applications \\
Spotify & Listening time & Subscription conversions \\
TikTok & User engagement & Creator satisfaction \\
Amazon & Click-through rate & Purchase revenue \\
\hline
\end{tabular}

This shows you've worked on real-world systems, not just textbook single-objective optimization.

\section{Feature Engineering for Recommendations}

\textbf{Feature categories:}

\textbf{1. User Features}
\begin{itemize}
\item \textbf{Demographics}: Age, gender, location, language
\item \textbf{Historical behavior}:
\begin{itemize}
\item \# clicks/watches in last 1h, 24h, 7d, 30d
\item \# purchases, avg basket size
\item Favorite categories (top 3-5)
\end{itemize}
\item \textbf{Temporal patterns}:
\begin{itemize}
\item Active hours (morning/afternoon/evening)
\item Weekday vs weekend behavior
\end{itemize}
\item \textbf{Session context}: Device, platform, current session length
\end{itemize}

\textbf{2. Item Features}
\begin{itemize}
\item \textbf{Content}: Title, description, category, tags, metadata
\item \textbf{Popularity}:
\begin{itemize}
\item View count (1h, 24h, 7d, all-time)
\item CTR, conversion rate
\item Trending score
\end{itemize}
\item \textbf{Quality}: User ratings, reviews, likes/dislikes ratio
\item \textbf{Freshness}: Upload time, time since publish
\end{itemize}

\textbf{3. User-Item Cross Features}
\begin{itemize}
\item \textbf{Historical interaction}:
\begin{itemize}
\item Has user viewed this item before?
\item Has user viewed similar items?
\item User's affinity to item category (CTR for category)
\end{itemize}
\item \textbf{Similarity scores}:
\begin{itemize}
\item Cosine similarity (user embedding, item embedding)
\item Category match score
\end{itemize}
\end{itemize}

\textbf{4. Context Features}
\begin{itemize}
\item \textbf{Time}: Hour of day, day of week, holiday/weekend
\item \textbf{Device}: Mobile/desktop, OS, browser
\item \textbf{Location}: City, country, timezone
\item \textbf{Session}: Pages viewed in session, time spent
\end{itemize}

\textbf{Feature Engineering Code:}
\begin{lstlisting}[language=Python]
import pandas as pd
import numpy as np

def engineer_features(user_id, item_id, context):
    features = {}

    # User features
    user_history = get_user_history(user_id, lookback_days=30)
    features['user_click_count_1h'] = count_clicks(user_history, hours=1)
    features['user_click_count_24h'] = count_clicks(user_history, hours=24)
    features['user_click_count_7d'] = count_clicks(user_history, days=7)
    features['user_avg_session_time'] = user_history['session_time'].mean()
    features['user_favorite_categories'] = get_top_categories(user_history, top_k=3)

    # Item features
    item_stats = get_item_stats(item_id)
    features['item_view_count_24h'] = item_stats['views_24h']
    features['item_ctr'] = item_stats['clicks'] / max(item_stats['impressions'], 1)
    features['item_age_hours'] = (datetime.now() - item_stats['publish_time']).total_seconds() / 3600
    features['item_category'] = item_stats['category']

    # Cross features
    features['user_item_category_affinity'] = get_category_affinity(user_id, item_stats['category'])
    features['user_viewed_before'] = item_id in user_history['item_ids']

    # User-item embedding similarity
    user_emb = get_user_embedding(user_id)
    item_emb = get_item_embedding(item_id)
    features['embedding_similarity'] = cosine_similarity(user_emb, item_emb)

    # Context features
    features['hour_of_day'] = context['timestamp'].hour
    features['is_weekend'] = context['timestamp'].weekday() >= 5
    features['device_type'] = context['device']

    return features
\end{lstlisting}

\section{Cold Start Solutions}

\textbf{Problem}: New users/items have no collaborative signals

\textbf{1. New User Cold Start}

\textbf{Approach A: Onboarding Survey}
\begin{itemize}
\item Ask user to select interests/preferences
\item Show popular items from selected categories
\item Netflix, Spotify use this approach
\end{itemize}

\textbf{Approach B: Demographic-Based}
\begin{itemize}
\item Use age, gender, location to find similar users
\item Recommend what similar users like
\end{itemize}

\textbf{Approach C: Explore Popular Items}
\begin{itemize}
\item Show trending/popular items
\item Collect feedback quickly to build profile
\end{itemize}

\begin{lstlisting}[language=Python]
def recommend_for_new_user(user_id, user_demographics):
    """Cold start recommendation for new user"""

    if has_onboarding_preferences(user_id):
        # Use stated preferences
        prefs = get_onboarding_preferences(user_id)
        candidates = get_items_by_categories(prefs['categories'], top_k=500)
    else:
        # Use demographics to find similar users
        similar_users = find_similar_users_by_demographics(user_demographics, top_k=100)

        # Aggregate their liked items
        candidates = aggregate_user_likes(similar_users, top_k=500)

        # Also add trending items (exploration)
        trending = get_trending_items(top_k=100)
        candidates.extend(trending)

    # Rank by popularity (no personalization signal yet)
    ranked = rank_by_popularity(candidates)

    return ranked[:50]
\end{lstlisting}

\textbf{2. New Item Cold Start}

\textbf{Approach A: Content-Based Bootstrap}
\begin{itemize}
\item Use item content (title, description, category)
\item Find similar existing items
\item Recommend to users who liked similar items
\end{itemize}

\begin{lstlisting}[language=Python]
def recommend_new_item(item_id):
    """Bootstrap recommendations for new item"""

    # Get item content features
    item_features = get_item_content(item_id)

    # Find similar items using content
    similar_items = find_similar_items_by_content(
        item_features,
        top_k=100
    )

    # Get users who liked similar items
    target_users = []
    for similar_item in similar_items:
        users = get_users_who_liked(similar_item)
        target_users.extend(users)

    # Deduplicate and rank by engagement level
    target_users = deduplicate_and_rank(target_users)

    return target_users[:1000]  # Show to these users
\end{lstlisting}

\textbf{Approach B: Creator-Based}
\begin{itemize}
\item If from known creator, show to creator's followers
\item YouTube, TikTok use this
\end{itemize}

\textbf{Approach C: Controlled Exploration}
\begin{itemize}
\item Show to small random sample (5-10\%)
\item Collect engagement data
\item Bootstrap collaborative signal
\end{itemize}

\section{Evaluation Metrics}

\subsection{Offline Metrics}

\textbf{1. Ranking Metrics}

\textbf{NDCG@K (Normalized Discounted Cumulative Gain):}
\begin{equation}
\text{DCG@K} = \sum_{i=1}^K \frac{2^{rel_i} - 1}{\log_2(i+1)}
\end{equation}
\begin{equation}
\text{NDCG@K} = \frac{\text{DCG@K}}{\text{IDCG@K}}
\end{equation}

\begin{lstlisting}[language=Python]
def ndcg_at_k(relevance_scores, k):
    """
    relevance_scores: List of relevance scores in ranked order
    Higher is better (e.g., [5, 3, 2, 0, 1, ...])
    """
    def dcg_at_k(scores, k):
        scores = np.array(scores)[:k]
        gains = 2**scores - 1
        discounts = np.log2(np.arange(2, len(scores) + 2))
        return np.sum(gains / discounts)

    dcg = dcg_at_k(relevance_scores, k)

    # Ideal DCG (best possible ordering)
    ideal_scores = sorted(relevance_scores, reverse=True)
    idcg = dcg_at_k(ideal_scores, k)

    if idcg == 0:
        return 0.0

    return dcg / idcg

# Example
relevance = [3, 2, 3, 0, 1, 2]  # User clicked items at positions 0, 1, 2, 5
print(f"NDCG@5: {ndcg_at_k(relevance, 5):.4f}")
\end{lstlisting}

\textbf{2. Diversity Metrics}

\textbf{Intra-List Similarity (ILS):}
\begin{equation}
\text{ILS} = \frac{2}{K(K-1)} \sum_{i=1}^K \sum_{j=i+1}^K \text{sim}(item_i, item_j)
\end{equation}

Lower ILS = More diverse list

\begin{lstlisting}[language=Python]
def intra_list_similarity(recommended_items, similarity_matrix):
    """
    Measure diversity of recommendation list
    """
    k = len(recommended_items)
    if k < 2:
        return 0.0

    total_similarity = 0
    count = 0

    for i in range(k):
        for j in range(i+1, k):
            total_similarity += similarity_matrix[recommended_items[i]][recommended_items[j]]
            count += 1

    return total_similarity / count
\end{lstlisting}

\textbf{3. Coverage Metrics}

\textbf{Catalog Coverage:}
\begin{equation}
\text{Coverage} = \frac{\text{\# unique items recommended}}{\text{Total \# items in catalog}}
\end{equation}

\begin{lstlisting}[language=Python]
def catalog_coverage(all_recommendations, catalog_size):
    """
    all_recommendations: List of lists, recommendations for each user
    """
    unique_items = set()
    for user_recs in all_recommendations:
        unique_items.update(user_recs)

    return len(unique_items) / catalog_size
\end{lstlisting}

\subsection{Online Metrics}

\textbf{Primary Business Metrics:}
\begin{itemize}
\item \textbf{CTR}: Clicks / Impressions
\item \textbf{Engagement time}: Total watch time, time on site
\item \textbf{Conversion rate}: Purchases / Clicks
\item \textbf{Revenue per user}: Total revenue / Active users
\end{itemize}

\textbf{User Retention:}
\begin{itemize}
\item \textbf{DAU / MAU}: Daily Active Users / Monthly Active Users
\item \textbf{Session frequency}: Sessions per user per week
\item \textbf{Churn rate}: \% users who stop using
\end{itemize}

\textbf{Guardrail Metrics:}
\begin{itemize}
\item \textbf{Latency}: p95, p99 recommendation latency
\item \textbf{Error rate}: \% failed recommendations
\item \textbf{Diversity}: Avg unique categories per user
\item \textbf{Freshness}: \% items published in last 24h
\end{itemize}

\section{A/B Testing for Recommendations}

\textbf{Setup:}
\begin{lstlisting}[language=Python]
import hashlib

def assign_experiment_group(user_id, experiment_name, num_groups=2):
    """Deterministic assignment to experiment groups"""
    hash_input = f"{experiment_name}:{user_id}"
    hash_value = int(hashlib.md5(hash_input.encode()).hexdigest(), 16)
    return hash_value % num_groups

# Usage
user_id = "12345"
group = assign_experiment_group(user_id, "two_tower_vs_cf_2024_01")

if group == 0:
    # Control: Collaborative filtering
    recommendations = cf_recommend(user_id)
else:
    # Treatment: Two-tower model
    recommendations = two_tower_recommend(user_id)
\end{lstlisting}

\textbf{Statistical Significance:}
\begin{lstlisting}[language=Python]
import scipy.stats as stats

def check_significance(control_clicks, control_impressions,
                       treatment_clicks, treatment_impressions,
                       alpha=0.05):
    """
    Two-proportion z-test for CTR
    """
    # CTR for each group
    p_control = control_clicks / control_impressions
    p_treatment = treatment_clicks / treatment_impressions

    # Pooled proportion
    p_pooled = (control_clicks + treatment_clicks) / (control_impressions + treatment_impressions)

    # Standard error
    se = np.sqrt(p_pooled * (1 - p_pooled) * (1/control_impressions + 1/treatment_impressions))

    # Z-score
    z = (p_treatment - p_control) / se

    # P-value (two-tailed)
    p_value = 2 * (1 - stats.norm.cdf(abs(z)))

    # Results
    is_significant = p_value < alpha
    lift = (p_treatment - p_control) / p_control * 100

    print(f"Control CTR: {p_control:.4f}")
    print(f"Treatment CTR: {p_treatment:.4f}")
    print(f"Lift: {lift:+.2f}%")
    print(f"P-value: {p_value:.4f}")
    print(f"Significant: {is_significant}")

    return is_significant, lift, p_value

# Example
check_significance(
    control_clicks=1000,
    control_impressions=50000,
    treatment_clicks=1100,
    treatment_impressions=50000
)
\end{lstlisting}

\section{Production Architecture}

\textbf{End-to-End System:}
\begin{verbatim}
┌──────────────────────────────────────────────────────────┐
│                   Data Collection                         │
│  User Events (clicks, views) → Kafka → Feature Store     │
└──────────────────────────────────────────────────────────┘
                            ↓
┌──────────────────────────────────────────────────────────┐
│                  Offline Training                         │
│  Daily Spark Job → Train Models → Model Registry         │
└──────────────────────────────────────────────────────────┘
                            ↓
┌──────────────────────────────────────────────────────────┐
│                Candidate Generation                       │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐     │
│  │     CF      │  │ Two-Tower   │  │  Sequential │     │
│  │  Retrieval  │  │  Retrieval  │  │  Retrieval  │     │
│  └─────────────┘  └─────────────┘  └─────────────┘     │
│         ↓                ↓                  ↓            │
│              10K Candidates                              │
└──────────────────────────────────────────────────────────┘
                            ↓
┌──────────────────────────────────────────────────────────┐
│                     Ranking                               │
│  DeepFM Model Server (TensorFlow Serving)                │
│  → Top 500 Items                                         │
└──────────────────────────────────────────────────────────┘
                            ↓
┌──────────────────────────────────────────────────────────┐
│                  Re-ranking                               │
│  Diversity (MMR) + Business Rules                        │
│  → Top 50 Items                                          │
└──────────────────────────────────────────────────────────┘
                            ↓
                    Return to User
\end{verbatim}

\textbf{Latency Budget:}
\begin{itemize}
\item Candidate generation: 50ms (parallel retrieval from multiple sources)
\item Ranking: 80ms (batch inference on GPU)
\item Re-ranking: 20ms (CPU-based MMR)
\item Total: 150ms (acceptable for most use cases)
\end{itemize}

\section{Interview Preparation}

\subsection{Sample Questions}

\textbf{1. Design YouTube Video Recommendations}
\begin{itemize}
\item Clarify: 2B users, 500M videos, homepage recommendations
\item Discuss: Two-tower vs matrix factorization
\item Address: Cold start for new videos, diversity, watch time optimization
\item Scale: ANN index sharding, embedding table size
\end{itemize}

\textbf{2. Design TikTok "For You" Feed}
\begin{itemize}
\item Emphasize: Sequential patterns (session-based)
\item Discuss: Real-time vs batch, freshness importance
\item Address: Virality detection, creator boost
\end{itemize}

\textbf{3. Design Amazon "Customers Who Bought This Also Bought"}
\begin{itemize}
\item Focus: Item-item CF, co-purchase matrix
\item Discuss: Real-time updates, complementary vs similar items
\end{itemize}

\subsection{Key Talking Points}

\textbf{Always mention:}
\begin{itemize}
\item \textbf{Multiple retrieval sources} (not just one algorithm)
\item \textbf{Trade-offs}: Accuracy vs diversity vs freshness
\item \textbf{Cold start solution} for new users/items
\item \textbf{Evaluation}: Both offline (NDCG) and online (CTR, engagement)
\item \textbf{A/B testing} strategy
\item \textbf{Scaling}: ANN search, embedding sharding
\end{itemize}

\textbf{Go deep on one area} (based on interviewer interest):
\begin{itemize}
\item Model architecture (two-tower, DeepFM, sequential)
\item Feature engineering (user/item/cross features)
\item Candidate generation (ANN search, blending)
\item Re-ranking (diversity, MMR, DPP)
\end{itemize}

\subsection{Recommended Resources}

\textbf{Papers:}
\begin{enumerate}
\item \textbf{Deep Neural Networks for YouTube Recommendations} (Covington et al., 2016)
\item \textbf{Wide \& Deep Learning for Recommender Systems} (Cheng et al., 2016)
\item \textbf{DeepFM} (Guo et al., 2017)
\item \textbf{GRU4Rec} (Hidasi et al., 2016)
\item \textbf{Self-Attentive Sequential Recommendation} (Kang \& McAuley, 2018)
\item \textbf{Deep Learning Recommendation Model (DLRM)} - Facebook (Naumov et al., 2019)
\end{enumerate}

\textbf{Blog Posts:}
\begin{itemize}
\item Netflix: Personalized Recommendations
\item Spotify: Discover Weekly
\item Pinterest: Homefeed Recommendations
\item Instagram: Explore Recommendations
\item TikTok: For You Algorithm
\end{itemize}

\section{The Future of Recommendations \& Strategic Bets}

At Principal level, you're not just executing current best practices—you're **guiding the company's long-term technical strategy**. This section covers emerging trends and how to position your organization for the future.

\subsection{LLMs in Recommendations: The Paradigm Shift}

Large Language Models are fundamentally changing how we think about recommendations. Understanding this evolution is critical for Principal-level interviews in 2024-2025.

\textbf{The Traditional Paradigm:}
\begin{itemize}
\item User embeddings + Item embeddings → Dot product → Top-K recommendations
\item Models trained on implicit feedback (clicks, watches)
\item No natural language understanding
\end{itemize}

\textbf{The LLM Paradigm:}
\begin{itemize}
\item Rich text understanding → Deep semantic representations
\item Ability to explain recommendations in natural language
\item Zero-shot generalization to new items/categories
\end{itemize}

\textbf{Approach 1: LLMs as Feature Extractors (Pragmatic, Happening Now)}

\textbf{Use case:} Replace hand-crafted text features with LLM embeddings

\textbf{Architecture:}
\begin{lstlisting}[language=Python]
import torch
from transformers import AutoModel, AutoTokenizer

class LLMFeatureExtractor:
    """Use LLM to create rich item embeddings from text"""
    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2'):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)
        self.model.eval()

    def extract_item_embedding(self, title, description, tags):
        """
        Convert unstructured text into dense embedding
        Input: "Product: iPhone 15. Description: Latest Apple..."
        Output: 384-dim embedding
        """
        # Combine all text fields
        text = f"Title: {title}. Description: {description}. Tags: {tags}"

        # Tokenize and encode
        inputs = self.tokenizer(text, return_tensors='pt',
                               truncation=True, max_length=512)

        with torch.no_grad():
            outputs = self.model(**inputs)
            # Use [CLS] token embedding
            embedding = outputs.last_hidden_state[:, 0, :].squeeze()

        return embedding.numpy()

# Integration with existing recommendation system
class HybridRecommender:
    """Combine LLM features with traditional CF features"""
    def __init__(self):
        self.llm_extractor = LLMFeatureExtractor()
        self.cf_model = TwoTowerModel()  # Traditional collaborative filtering

    def get_item_features(self, item):
        # LLM features from text
        llm_emb = self.llm_extractor.extract_item_embedding(
            item.title, item.description, item.tags
        )

        # Traditional CF features
        cf_emb = self.cf_model.item_tower(item.id)

        # Concatenate or weighted sum
        combined = torch.cat([llm_emb, cf_emb])
        return combined
\end{lstlisting}

\textbf{Real-world examples:}
\begin{itemize}
\item \textbf{Netflix}: Uses sentence transformers to embed plot summaries, combine with CF signals
\item \textbf{Spotify}: LLM embeddings for podcast descriptions, music reviews
\item \textbf{Pinterest}: CLIP (vision-language model) for image-text understanding
\end{itemize}

\textbf{Benefits:}
\begin{itemize}
\item \textbf{Cold start}: New items with good descriptions get meaningful embeddings immediately
\item \textbf{Semantic understanding}: "wireless earbuds" matches "Bluetooth headphones"
\item \textbf{Cross-lingual}: Multilingual models work across languages
\end{itemize}

\textbf{Costs:}
\begin{itemize}
\item \textbf{Inference cost}: \$0.001-\$0.01 per item (vs \$0.00001 for traditional lookup)
\item \textbf{Latency}: 50-200ms for LLM forward pass (can batch + cache)
\item \textbf{Complexity}: Need GPU infrastructure, model updates
\end{itemize}

\textbf{Interview talking point:} "I'd use a lightweight sentence transformer (384-dim) to embed item descriptions offline, then cache in feature store. This gives us semantic understanding for \$500/month in compute, vs building a custom NLP pipeline."

\textbf{Approach 2: LLMs as the Recommender (Futuristic, Research-y)}

\textbf{Use case:} Frame recommendation as a text generation task

\textbf{Prompt-based recommendation:}
\begin{verbatim}
Input prompt:
"User has watched:
1. Inception (sci-fi thriller, 2010)
2. Interstellar (sci-fi drama, 2014)
3. The Prestige (mystery thriller, 2006)

Based on this history, recommend 5 movies the user would enjoy.
For each recommendation, explain why."

LLM Output:
1. Shutter Island (2010) - Psychological thriller with complex plot twists,
   similar to The Prestige's mind-bending narrative.
2. Arrival (2016) - Intelligent sci-fi like Interstellar, explores deep
   concepts through human lens.
3. ...
\end{verbatim}

\textbf{Implementation sketch:}
\begin{lstlisting}[language=Python]
from openai import OpenAI

class LLMRecommender:
    def __init__(self):
        self.client = OpenAI()

    def recommend(self, user_history, k=5):
        # Build prompt from user history
        history_text = self._format_history(user_history)

        prompt = f"""User has watched:
{history_text}

Recommend {k} movies the user would enjoy. For each, explain why."""

        response = self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7
        )

        recommendations = self._parse_response(response.choices[0].message.content)
        return recommendations

    def _format_history(self, items):
        return "\n".join([f"{i+1}. {item.title} ({item.genre}, {item.year})"
                         for i, item in enumerate(items)])
\end{lstlisting}

\textbf{Benefits:}
\begin{itemize}
\item \textbf{Natural language explanations}: "Recommended because you liked Inception's plot twists"
\item \textbf{Zero-shot generalization}: Works on new categories without retraining
\item \textbf{Contextual reasoning}: Can incorporate time-of-day, mood, recent events
\item \textbf{Conversational refinement}: User can say "No thrillers, only comedies" → instant adaptation
\end{itemize}

\textbf{Costs (Why This Isn't Production-Ready Yet):}
\begin{itemize}
\item \textbf{Extreme inference cost}: \$0.01-\$0.10 per recommendation (100-1000x more expensive)
\item \textbf{Latency}: 1-5 seconds (vs 10ms for traditional ranker)
\item \textbf{Lack of control}: Can't enforce business rules, diversity, or fairness constraints easily
\item \textbf{Hallucinations}: Might recommend non-existent movies
\item \textbf{No explicit optimization}: Can't directly optimize for click-through rate or watch time
\end{itemize}

\textbf{When LLM-as-recommender makes sense:}
\begin{itemize}
\item \textbf{Low-frequency, high-value decisions}: Luxury purchases, major life decisions
\item \textbf{Explainability critical}: Medical recommendations, financial advice
\item \textbf{Small catalog}: 1000s of items, not millions
\item \textbf{Budget allows}: Can afford \$0.10 per recommendation
\end{itemize}

\textbf{Interview framework - The Hybrid Future:}

\textit{"For YouTube-scale recommendations (billions of impressions/day), I'd use:}
\begin{enumerate}
\item \textbf{Retrieval}: Traditional ANN search on collaborative filtering embeddings (< 1ms, \$0.00001/request)
\item \textbf{Ranking}: Two-tower model enhanced with LLM-generated item embeddings (10ms, \$0.0001/request)
\item \textbf{Re-ranking}: For top-10 results, use small fine-tuned LLM to generate explanation snippets (50ms, \$0.001/request)
\end{enumerate}

\textit{This balances cost (\$0.0011 total vs \$0.10 for pure LLM) and quality (semantic understanding + personalization)."}

\textbf{The 2025-2026 Bet: Specialized Recommendation LLMs}

Predict that we'll see:
\begin{itemize}
\item \textbf{Small, fast, domain-specific models}: 1B-7B parameters, fine-tuned on rec data
\item \textbf{Hybrid architectures}: LLM encoder + traditional ranking head
\item \textbf{Cost reduction}: 10-100x cheaper than GPT-4 via model compression
\item \textbf{Controllable generation}: RLHF to optimize for business metrics
\end{itemize}

\subsection{Multi-Modal \& Cross-Domain Recommendations}

\textbf{The Principal-Level Vision:}

Instead of building separate recommenders for videos, articles, products, music—can we build **one unified model**?

\textbf{Why it matters:}
\begin{itemize}
\item \textbf{Organizational leverage}: One team, one platform, serves all product lines
\item \textbf{Better representations}: Learn that "users who watch cooking videos buy kitchen gadgets"
\item \textbf{Cold start solved}: New video can leverage knowledge from 10 years of e-commerce data
\item \textbf{Personalization across products}: Understand user holistically, not per-app
\end{itemize}

\textbf{The Technical Challenge:}

Different modalities have different:
\begin{itemize}
\item \textbf{Features}: Videos (visual, audio, subtitles), Products (images, specs, price), Articles (text, author)
\item \textbf{Interaction signals}: Click, purchase, watch-time, share
\item \textbf{Catalogs}: 1M videos vs 100M products vs 10K music artists
\item \textbf{Objectives}: Maximize watch-time vs revenue vs engagement
\end{itemize}

\textbf{Approach: Unified Embedding Space}

\textbf{Architecture:}
\begin{lstlisting}[language=Python]
class UnifiedRecommender(nn.Module):
    """Single model for videos, products, articles, music"""
    def __init__(self, user_dim=256, item_dim=256, unified_dim=512):
        super().__init__()

        # User tower (shared across all domains)
        self.user_tower = nn.Sequential(
            nn.Linear(user_dim, 512),
            nn.ReLU(),
            nn.Linear(512, unified_dim)
        )

        # Modality-specific item encoders
        self.video_encoder = VideoEncoder(output_dim=item_dim)
        self.product_encoder = ProductEncoder(output_dim=item_dim)
        self.article_encoder = ArticleEncoder(output_dim=item_dim)

        # Project to unified space
        self.item_projection = nn.Linear(item_dim, unified_dim)

    def forward(self, user_features, item, item_type):
        # User representation (same for all item types)
        user_emb = self.user_tower(user_features)

        # Item representation (modality-specific encoder)
        if item_type == 'video':
            item_emb = self.video_encoder(item)
        elif item_type == 'product':
            item_emb = self.product_encoder(item)
        elif item_type == 'article':
            item_emb = self.article_encoder(item)

        # Project to unified space
        item_emb = self.item_projection(item_emb)

        # Score in unified space
        score = torch.dot(user_emb, item_emb)
        return score

# Cross-domain training
def cross_domain_loss(model, batch):
    """
    Batch contains multiple item types
    Learn unified user representation that works for all
    """
    user_emb = model.user_tower(batch['user_features'])

    losses = []
    for item_type in ['video', 'product', 'article']:
        if item_type in batch:
            item_emb = model.encode_item(batch[item_type], item_type)
            score = torch.dot(user_emb, item_emb)
            label = batch[f'{item_type}_label']
            loss = nn.BCELoss()(score, label)
            losses.append(loss)

    return sum(losses) / len(losses)  # Average across domains
\end{lstlisting}

\textbf{Real-world examples:}
\begin{itemize}
\item \textbf{Google}: One user embedding for Search, YouTube, Play Store, News
\item \textbf{Amazon}: Unified recommendations for products, Prime Video, Kindle books
\item \textbf{Meta}: Single user model for Feed, Stories, Reels, Marketplace
\end{itemize}

\textbf{Benefits:}
\begin{itemize}
\item \textbf{Transfer learning}: Video-watching behavior informs product recommendations
\item \textbf{Data efficiency}: 100M video interactions + 1B product interactions = better user understanding
\item \textbf{Cold start}: New user watches 3 videos → can already recommend products
\item \textbf{Organizational efficiency}: One platform team, not five domain-specific teams
\end{itemize}

\textbf{Challenges:}
\begin{itemize}
\item \textbf{Negative transfer}: Music listening patterns might not correlate with e-commerce
\item \textbf{Domain imbalance}: If 90\% of data is videos, model might underfit products
\item \textbf{Conflicting objectives}: Watch-time vs purchase revenue—which to optimize?
\item \textbf{Serving complexity}: Need to query multiple item types simultaneously
\end{itemize}

\textbf{Interview Strategy - The Phased Approach:}

\textit{"To build a unified recommender for Google (Search, YouTube, News, Shopping):}

\textbf{Phase 1 (Year 1)}: Build separate recommenders, but with **aligned user embeddings**
\begin{itemize}
\item Shared user tower, domain-specific item towers
\item Prove that unified user representation helps all domains
\item Metrics: Watch time (YouTube), CTR (Search), purchases (Shopping)
\end{itemize}

\textbf{Phase 2 (Year 2)}: Add cross-domain signals
\begin{itemize}
\item "Users who search for 'cameras' → recommend photography YouTube channels"
\item Measure lift: Does cross-domain signal improve recommendations?
\end{itemize}

\textbf{Phase 3 (Year 3)}: Fully unified platform
\begin{itemize}
\item Single API: recommend(user, context) → ranked list of videos/products/articles
\item Multi-objective optimization: Balance engagement across all surfaces
\item Platform team owns user understanding company-wide
\end{itemize}

\textbf{Success metrics}:
\begin{itemize}
\item Time from 'new content type' to 'production recommender': 3 months → 2 weeks
\item Organizational leverage: 10 engineers support 100+ product teams
\item Business impact: 15\% lift in engagement from cross-domain signals
\end{itemize}"

\textbf{Key Interview Talking Points:}

When asked about the future of recommendations, demonstrate Principal-level vision:

\begin{enumerate}
\item \textbf{"LLMs will augment, not replace, traditional rec systems in the next 2-3 years"}
\begin{itemize}
\item Use LLMs as feature extractors (pragmatic, cost-effective)
\item Reserve LLM-as-recommender for high-value, low-frequency use cases
\item Expect specialized small models (1B-7B params) to emerge
\end{itemize}

\item \textbf{"The winning strategy is cross-domain user understanding"}
\begin{itemize}
\item Companies with multiple surfaces (video + e-commerce + social) have an advantage
\item Unified user embeddings enable transfer learning and cold start
\item But start with domain-specific models, evolve to unified platform
\end{itemize}

\item \textbf{"Multi-modal models (CLIP, Flamingo) unlock new recommendation paradigms"}
\begin{itemize}
\item Recommend products based on video content ("buy the jacket from that TikTok")
\item Image-to-product search ("find me this outfit")
\item Text-to-video ("show me tutorials on...") with semantic understanding
\end{itemize}

\item \textbf{"The cost curve matters"}
\begin{itemize}
\item Pure LLM recommendations cost 100-1000x more than traditional
\item But as models compress (distillation, quantization), economics shift
\item By 2026, expect 10x cost reduction → makes LLMs viable for high-QPS
\end{itemize}
\end{enumerate}

This shows you're not just executing today's playbook—you're **positioning the organization for the next 5 years**.

\section{Conclusion}

Recommendation systems differ from search in fundamental ways:
\begin{itemize}
\item \textbf{No explicit query} → Must predict user preferences
\item \textbf{Collaborative signals} dominate over content
\item \textbf{Multiple objectives}: Relevance + Diversity + Novelty
\item \textbf{Sequential patterns} matter (user journey)
\end{itemize}

\textbf{Key takeaways for interviews:}
\begin{enumerate}
\item Master the three-stage funnel (retrieval → ranking → re-ranking)
\item Know modern deep learning architectures (two-tower, DeepFM, sequential models)
\item Understand production concerns (cold start, diversity, scaling)
\item Practice calculating: embedding size, latency budget, A/B test significance
\end{enumerate}

This guide should refresh your recommendations knowledge from your search background and prepare you for Staff/Principal level discussions!

\end{document}
